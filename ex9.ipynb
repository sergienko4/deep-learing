{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSYoPiIREg1A"
      },
      "source": [
        "# Deep Learning: Ex.9 - Generative Adversarial Networks (GAN)\n",
        "\n",
        "Submitted by: [... **namd and ID** ...]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iv07K1SbEg1D"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Reshape, Flatten, Dropout, Input\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, LeakyReLU\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOXRVgdqE_A6"
      },
      "source": [
        "---\n",
        "### Loading the dataset\n",
        "\n",
        "This dataset contains ~20K anime-face images (each image is 64x64 pixels):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgHDqqBGE9zk"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "from zipfile import ZipFile\n",
        "\n",
        "url = \"https://drive.google.com/uc?id=1ouH9kAGuZqTqknLvzDLiKRfCF0aqCROD\"\n",
        "gdown.download(url, 'data.zip', quiet=False)  # ~ 480MB\n",
        "\n",
        "print('unzipping...')\n",
        "with ZipFile(\"data.zip\", \"r\") as zipobj:\n",
        "    zipobj.extractall()  # unzip the file\n",
        "\n",
        "print('done.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzJ4IcnkFUtH"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "dataGen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "dataset = dataGen.flow_from_directory('anime_data', target_size=(64,64), batch_size=25000, class_mode='sparse').next()[0]\n",
        "print('dataset.shape =',dataset.shape)\n",
        "\n",
        "# plot some samples:\n",
        "plt.figure(figsize=(12,6))\n",
        "for i in range(50):\n",
        "\t\tplt.subplot(5, 10, 1 + i)\n",
        "\t\tplt.axis('off')\n",
        "\t\tplt.imshow(dataset[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpuqKEhzEg1D"
      },
      "source": [
        "***\n",
        "\n",
        "### 1. Training a GAN model \n",
        "\n",
        "- Use our model developed in the class presentation, and adjust its architecture to match the new dataset images shape: `(64,64,3)`.\n",
        "\n",
        "- Use a latent dimension of 20-D as the noise input for the generator model.\n",
        "\n",
        "- Generate 12 noise vectors (each one is of 20-D), and use these vectors to generate 12 images from the (un-trained) generator. Display the images in a single row of sublplots.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGr2AdSmEg1E"
      },
      "outputs": [],
      "source": [
        "###########################\n",
        "###  your code here...  ###\n",
        "###########################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsJoHoREIJq2"
      },
      "source": [
        "- Train the GAN model for 50-100 epochs (it take ~1min/epoch).\n",
        "\n",
        "- After each and every epoch, feed the **same** 12 noise vectors to the generator, and plot a generated images. This will help you follow the training progress. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzEToT96IJ89"
      },
      "outputs": [],
      "source": [
        "###########################\n",
        "###  your code here...  ###\n",
        "###########################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ojNxV0yEg1F"
      },
      "source": [
        "***\n",
        "\n",
        "### 2. Exploring the latent (input) space\n",
        "\n",
        "- Generate and display 64 **new** images from the generator (use 8x8 subplots).\n",
        "\n",
        "- Pick a single \"good\" image out of these images, and denote the seed-vector that generated it by `z`.\n",
        "\n",
        "- Next, generate 25 new seed vectors, based on this specific `z`, in the following way:\n",
        "\n",
        " - We will add a small-variance noise vector `dz` (a.k.a pertubation, also of 20-D) to `z`, and feed the new vector (`z + dz`) to the generator, to generate a new image. \n",
        "  - Use a Normal distribution with $\\sigma=0.5$ for the pertubation `dz` (you can experiment with different values for $\\sigma$).\n",
        "\n",
        "- Repeat this process to generate a total of 25 new images (each generated from the same seed `z` but with a different pertubation `dz`).\n",
        "\n",
        "- Display the results (use 5x5 subplots)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpPmzkLpEg1F"
      },
      "outputs": [],
      "source": [
        "    ###########################\n",
        "    ###  your code here...  ###\n",
        "    ###########################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoDPkEymEg1G"
      },
      "source": [
        "***\n",
        "### 3. Morphing between two images\n",
        "\n",
        "\n",
        "- Pick 2 out of the 64 examples you've generated in Q2. Denote the seed-vectors that generated these images by `z1` and `z2`.\n",
        "\n",
        "- We will try to \"morph\" between these two images, by \"walking\" in the latent space from `z1` to `z2`.\n",
        "\n",
        " - Generate a set of 10 seed-vectors, using a linear interpolation (by varying $\\alpha$ from 1 to 0):\n",
        "\n",
        "$$ \\vec{z}_{interp} \\ \\ =\\ \\  \\alpha \\cdot \\vec{z_1} \\ \\ +\\ \\  (1-\\alpha) \\cdot \\vec{z_2}$$\n",
        "\n",
        "- Feed the interpolated seed vectors to the generator and display the sequence of images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7f-4LlRpEg1G"
      },
      "outputs": [],
      "source": [
        "###########################\n",
        "###  your code here...  ###\n",
        "###########################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfqTyhfWSn_f"
      },
      "source": [
        "- Extend the last process to morph between 3 different images `I1`, `I2`, `I3`:\n",
        " - Generate a morphing sequence from `I1` to `I2`, from `I2` to `I3`, and from `I3` back to `I1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1jfdByqSRjs"
      },
      "outputs": [],
      "source": [
        "###########################\n",
        "###  your code here...  ###\n",
        "###########################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNPBjJH6TLfM"
      },
      "source": [
        "- Finally, if you wish, you can generate an animated GIF of your generated sequence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfiXwmYPTL1f"
      },
      "outputs": [],
      "source": [
        "anim_file = 'animation.gif'\n",
        "\n",
        "import imageio\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer:\n",
        "    # loop over the images you want to add to the animated GIF file\n",
        "    # use: writer.append_data(your_image)\n",
        "    # where your_image should be np.uint8 format, with values from 0-255.\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRBbnxSGEg1J"
      },
      "source": [
        "***\n",
        "## Good Luck!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ex9.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
