{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergienko4/deep-learing/blob/main/ex10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaMoU7zn9R_P"
      },
      "source": [
        "# Deep Learning: Ex.10 - RNN\n",
        "\n",
        "Submitted by: [... **your name and ID** ...]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oN_6bfHZ9R_S",
        "outputId": "758b048e-cbe3-4a12-e379-212e8011de6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM # <--- recurrent layers\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from seaborn import heatmap\n",
        "import re\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path='/content/drive/MyDrive/ex10/war_and_peace.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ0BtfeM9bli",
        "outputId": "2c466aaa-1d21-46ef-ad67-3fbbfd9e66b3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8i2f2p29R_V"
      },
      "source": [
        "***\n",
        "### 1. Preprocess the text corpus\n",
        "\n",
        "(if you are using google colab, remember to upload the corpus file first..)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L8JLzkR9R_X",
        "outputId": "eb835c1e-7152-42eb-fd90-85aeb312fcb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(text) =  3196213\n",
            "well prince so genoa and lucca are now just family estates of the buonapartes but i warn you if you dont tell me that this means war if you still try to defend the infamies and horrors perpetrated by that antichristi really believe he is antichristi will have nothing more to do with you and you are no longer my friend no longer my faithful slave as you call yourself but how do you do i see i have \n"
          ]
        }
      ],
      "source": [
        "# f = open('war_and_peace.txt','r') # open the corpus file\n",
        "f = open(path,'r') \n",
        "text = f.read().lower()  # read file and convert to lower-case letters\n",
        "data = text.replace('\\n',' ')\n",
        "\n",
        "data = re.sub(r'[^a-zA-Z0-9 ]',r'',data)\n",
        "\n",
        "print('len(text) = ',len(text))\n",
        "\n",
        "print(data[:400]) # print the first 400 characters.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C86ydp0A9R_Y"
      },
      "source": [
        "- generate training sequences of `T=20` characters, by sampling the text corpus with a stride of 5 characters (i.e., each sequences starts 5 chars after the begining of the last sequences).\n",
        "\n",
        "- generate a matching list, holding the `next_char` for each of your sequences.\n",
        "\n",
        "- how many sequences did you extract in total? `N = ?`\n",
        "\n",
        "- convert the sequences into a 1-hot representation, suitable for our model trainig:\n",
        "\n",
        "`X.shape = (N, T, len(chars))`\n",
        "\n",
        "`Y.shape = (N, len(chars))`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(data)))\n",
        "data_size, vocab_size = len(data), len(chars)\n",
        "print('There are %d total characters and %d unique characters in your data.' % (data_size, vocab_size))\n",
        "print('chars = ',chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsmUFYMIEj43",
        "outputId": "8c9820a3-fbc3-4c11-ae2b-a2b705fcc11f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 3083435 total characters and 37 unique characters in your data.\n",
            "chars =  [' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
        "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
        "\n",
        "# ix_to_char"
      ],
      "metadata": {
        "id": "O7zbsDRSE8il"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T = 20  # extract training sequences of length T\n",
        "stride = 5\n",
        "\n",
        "sequences = []  # This holds our extracted sequences\n",
        "next_chars = []  # This holds the targets (the follow-up character)\n",
        "\n",
        "for i in range(0, len(data) - T, stride):\n",
        "    sequences.append(data[i: i + T])\n",
        "    next_chars.append(data[i + T])"
      ],
      "metadata": {
        "id": "9gLw2yBjFqMp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(sequences), T, len(chars)), dtype='bool')\n",
        "Y = np.zeros((len(sequences), len(chars)), dtype='bool')\n",
        "\n",
        "for i, seq in enumerate(sequences):\n",
        "    for t, char in enumerate(seq):\n",
        "        X[i, t, char_to_ix[char]] = 1\n",
        "    Y[i, char_to_ix[next_chars[i]]] = 1\n",
        "    \n",
        "print('X.shape = (#examples, T, input-dim) =', X.shape)\n",
        "print('Y.shape = (#examples, output-dim) =', Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqQgDtlDFyHV",
        "outputId": "71f7bb43-a4d3-48fc-8133-70a6d69b976e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape = (#examples, T, input-dim) = (616683, 20, 37)\n",
            "Y.shape = (#examples, output-dim) = (616683, 37)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15DwlbpW9R_b"
      },
      "source": [
        "***\n",
        "### 2. LTSM Model\n",
        "\n",
        "- Build an `LTSM` model with 128 (hidden)-units that accepts the input sequences. Add a `Dense` layer on top of it, with `len(chars)` softmax units.\n",
        "\n",
        "- Train the model for only 1 epoch (use: `RMSprop` and batch size of 128).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential(name='LSTM_128')\n",
        "model.add(Input(shape=(T, len(chars))))  # (12,27)\n",
        "model.add(LSTM(128)) # 128 internal state units\n",
        "model.add(Dense(len(chars), activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "XH4ux8GdMazW",
        "outputId": "062455f9-6ab4-447f-fd1f-b1fa3d86709e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"LSTM_128\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128)               84992     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 37)                4773      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 89,765\n",
            "Trainable params: 89,765\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "history = model.fit(X, Y, epochs=1, batch_size=128)"
      ],
      "metadata": {
        "id": "SVta-HkVNVD8",
        "outputId": "4d525aaf-44ad-47e5-9afc-d3c2c061c4f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4818/4818 [==============================] - 25s 4ms/step - loss: 2.0242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjfbZqIZ9R_d"
      },
      "source": [
        "### 3. Model predictions\n",
        "\n",
        "\n",
        "- use the senternce `the meaning of life ` as an input to the model (convert it to 1-hot first..),\n",
        "\n",
        "- plot the model's output as a probability distribution over the list of chars.\n",
        "\n",
        "- sample a single char from that distribution, and add it to the generated sentence.\n",
        "\n",
        "- update the 1-hot buffer, and continue the process for 99 more letters (using a loop).\n",
        "\n",
        "- print the resulting sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QdnGKgvU9R_e"
      },
      "outputs": [],
      "source": [
        "input = 'the meaning of life'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_one_hot = np.zeros((len(input), T, len(chars)), dtype='bool')"
      ],
      "metadata": {
        "id": "p1NTrpq-OZhy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_one_hot.shape"
      ],
      "metadata": {
        "id": "j0xk3tYdP3Yf",
        "outputId": "f2cbf642-f5ea-48af-aabc-d06359b7b5ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19, 20, 37)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = model.predict(input_one_hot)"
      ],
      "metadata": {
        "id": "4iolT6PkOqJU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14,4))\n",
        "plt.bar(range(len(chars)), y_hat[0])\n",
        "plt.xticks(range(len(chars)), labels=chars)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LRuGNqAIPIWs",
        "outputId": "36a25366-40a3-44fb-f4d1-f74e78d1ee1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_buffer = input_one_hot[0]\n",
        "generated_text = input\n",
        "\n",
        "yy = []\n",
        "for i in range(100):\n",
        "    yhat = model.predict(input_buffer[None,:])\n",
        "    # sample the next character:\n",
        "    # ix = np.argmax(yhat)\n",
        "    ix = np.random.choice(range(len(chars)), p=yhat[0])\n",
        "    ch = ix_to_char[ix]\n",
        "    generated_text += ch\n",
        "    # update the input buffer:\n",
        "    input_buffer = np.r_[input_buffer[1:,:], np.zeros((1,len(chars)))]\n",
        "    input_buffer[-1,ix] = 1\n",
        "    yy.append(yhat)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "hLgnagExUDR0",
        "outputId": "2538b908-b2ae-40e1-839b-2235e5491dda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the meaning of lifeicaly of a nemesing peesrouz spribe that byeced sheaw why hived at go he frin dule liagh thay  worta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uaqpz4zJ9R_f"
      },
      "source": [
        "***\n",
        "### 3. Fit your model\n",
        "\n",
        "- Fit your model a bit more (try 10-20 epochs), and regenerate a new `N=100` sentence sample. Does it get any better?\n",
        "\n",
        "- If you wish, you can try to train the model further, or you can try using a different corpus (dataset) for the training (you can even try a text in hebrew). Be creative ;)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, Y, epochs=20, batch_size=128)"
      ],
      "metadata": {
        "id": "ts6vlqWEUm5O",
        "outputId": "f26fa280-3b18-49ce-92df-5e9a4dffc3b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.6471\n",
            "Epoch 2/20\n",
            "4818/4818 [==============================] - 17s 4ms/step - loss: 1.5177\n",
            "Epoch 3/20\n",
            "4818/4818 [==============================] - 20s 4ms/step - loss: 1.4458\n",
            "Epoch 4/20\n",
            "4818/4818 [==============================] - 17s 4ms/step - loss: 1.3991\n",
            "Epoch 5/20\n",
            "4818/4818 [==============================] - 17s 4ms/step - loss: 1.3648\n",
            "Epoch 6/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.3386\n",
            "Epoch 7/20\n",
            "4818/4818 [==============================] - 17s 4ms/step - loss: 1.3179\n",
            "Epoch 8/20\n",
            "4818/4818 [==============================] - 17s 4ms/step - loss: 1.3006\n",
            "Epoch 9/20\n",
            "4818/4818 [==============================] - 17s 4ms/step - loss: 1.2865\n",
            "Epoch 10/20\n",
            "4818/4818 [==============================] - 17s 4ms/step - loss: 1.2742\n",
            "Epoch 11/20\n",
            "4818/4818 [==============================] - 17s 4ms/step - loss: 1.2634\n",
            "Epoch 12/20\n",
            "4818/4818 [==============================] - 17s 4ms/step - loss: 1.2544\n",
            "Epoch 13/20\n",
            "4818/4818 [==============================] - 17s 4ms/step - loss: 1.2460\n",
            "Epoch 14/20\n",
            "4818/4818 [==============================] - 17s 4ms/step - loss: 1.2385\n",
            "Epoch 15/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.2319\n",
            "Epoch 16/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.2255\n",
            "Epoch 17/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.2203\n",
            "Epoch 18/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.2151\n",
            "Epoch 19/20\n",
            "4818/4818 [==============================] - 17s 4ms/step - loss: 1.2104\n",
            "Epoch 20/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.2064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nL10liRv9R_g",
        "outputId": "4d64bece-d103-48dc-aa0b-f0b2bf16040c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the meaning of lifejjxqxapace on the bading of your houseny off he should see him to hapty calm and belonged by his inf\n"
          ]
        }
      ],
      "source": [
        "input_buffer = input_one_hot[0]\n",
        "generated_text = input\n",
        "\n",
        "yy = []\n",
        "for i in range(100):\n",
        "    yhat = model.predict(input_buffer[None,:])\n",
        "    # sample the next character:\n",
        "    # ix = np.argmax(yhat)\n",
        "    ix = np.random.choice(range(len(chars)), p=yhat[0])\n",
        "    ch = ix_to_char[ix]\n",
        "    generated_text += ch\n",
        "    # update the input buffer:\n",
        "    input_buffer = np.r_[input_buffer[1:,:], np.zeros((1,len(chars)))]\n",
        "    input_buffer[-1,ix] = 1\n",
        "    yy.append(yhat)\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "wvtNTixKgW9t",
        "outputId": "92ba7a69-0038-4ce5-f64a-557283beef56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(616683, 20, 37)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#---------------------------------------------------freestyle---------------------------------------------------"
      ],
      "metadata": {
        "id": "RXeWpx4utCH1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_freestyle = Sequential(name='freestyle')\n",
        "model_freestyle.add(LSTM(\n",
        "        256,\n",
        "        input_shape=(X.shape[1], X.shape[2]),\n",
        "        return_sequences=True\n",
        "    ))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(LSTM(512, return_sequences=True))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(LSTM(256))\n",
        "model_freestyle.add(Dense(256))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(Dense(vocab_size))\n",
        "model_freestyle.add(Activation('softmax'))\n",
        "model_freestyle.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "model_freestyle.summary()\n"
      ],
      "metadata": {
        "id": "F3350UHwfT1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a784778-cb91-404d-fec3-5b600c3c6f94"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"freestyle\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_1 (LSTM)               (None, 20, 256)           301056    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 20, 256)           0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 20, 512)           1574912   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 20, 512)           0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 256)               787456    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 37)                9509      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 37)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,738,725\n",
            "Trainable params: 2,738,725\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_freestyle.fit(X, Y, epochs=70, batch_size=1024)"
      ],
      "metadata": {
        "id": "uvwsS5cyhD_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d556e727-7983-4274-a7c5-35044d958bd7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "603/603 [==============================] - 43s 65ms/step - loss: 2.3118\n",
            "Epoch 2/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 1.6868\n",
            "Epoch 3/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 1.4632\n",
            "Epoch 4/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 1.3578\n",
            "Epoch 5/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 1.2951\n",
            "Epoch 6/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 1.2492\n",
            "Epoch 7/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 1.2144\n",
            "Epoch 8/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 1.1852\n",
            "Epoch 9/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 1.1590\n",
            "Epoch 10/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 1.1371\n",
            "Epoch 11/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 1.1155\n",
            "Epoch 12/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 1.0957\n",
            "Epoch 13/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 1.0788\n",
            "Epoch 14/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 1.0608\n",
            "Epoch 15/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 1.0440\n",
            "Epoch 16/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 1.0284\n",
            "Epoch 17/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 1.0138\n",
            "Epoch 18/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 1.0000\n",
            "Epoch 19/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.9869\n",
            "Epoch 20/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.9745\n",
            "Epoch 21/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.9623\n",
            "Epoch 22/70\n",
            "603/603 [==============================] - 39s 66ms/step - loss: 0.9516\n",
            "Epoch 23/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.9406\n",
            "Epoch 24/70\n",
            "603/603 [==============================] - 40s 66ms/step - loss: 0.9300\n",
            "Epoch 25/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.9218\n",
            "Epoch 26/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.9114\n",
            "Epoch 27/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.9031\n",
            "Epoch 28/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.8952\n",
            "Epoch 29/70\n",
            "603/603 [==============================] - 40s 66ms/step - loss: 0.8867\n",
            "Epoch 30/70\n",
            "603/603 [==============================] - 40s 66ms/step - loss: 0.8799\n",
            "Epoch 31/70\n",
            "603/603 [==============================] - 40s 66ms/step - loss: 0.8728\n",
            "Epoch 32/70\n",
            "603/603 [==============================] - 40s 66ms/step - loss: 0.8661\n",
            "Epoch 33/70\n",
            "603/603 [==============================] - 40s 66ms/step - loss: 0.8601\n",
            "Epoch 34/70\n",
            "603/603 [==============================] - 40s 66ms/step - loss: 0.8533\n",
            "Epoch 35/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.8475\n",
            "Epoch 36/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.8422\n",
            "Epoch 37/70\n",
            "603/603 [==============================] - 40s 66ms/step - loss: 0.8375\n",
            "Epoch 38/70\n",
            "603/603 [==============================] - 40s 66ms/step - loss: 0.8315\n",
            "Epoch 39/70\n",
            "603/603 [==============================] - 40s 66ms/step - loss: 0.8282\n",
            "Epoch 40/70\n",
            "603/603 [==============================] - 40s 66ms/step - loss: 0.8221\n",
            "Epoch 41/70\n",
            "603/603 [==============================] - 40s 66ms/step - loss: 0.8182\n",
            "Epoch 42/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.8140\n",
            "Epoch 43/70\n",
            "603/603 [==============================] - 40s 66ms/step - loss: 0.8097\n",
            "Epoch 44/70\n",
            "603/603 [==============================] - 40s 66ms/step - loss: 0.8044\n",
            "Epoch 45/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.7998\n",
            "Epoch 46/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.7970\n",
            "Epoch 47/70\n",
            "603/603 [==============================] - 40s 66ms/step - loss: 0.7935\n",
            "Epoch 48/70\n",
            "603/603 [==============================] - 40s 66ms/step - loss: 0.7913\n",
            "Epoch 49/70\n",
            "603/603 [==============================] - 40s 66ms/step - loss: 0.7860\n",
            "Epoch 50/70\n",
            "603/603 [==============================] - 40s 66ms/step - loss: 0.7833\n",
            "Epoch 51/70\n",
            "603/603 [==============================] - 40s 66ms/step - loss: 0.7791\n",
            "Epoch 52/70\n",
            "603/603 [==============================] - 40s 66ms/step - loss: 0.7741\n",
            "Epoch 53/70\n",
            "603/603 [==============================] - 40s 66ms/step - loss: 0.7700\n",
            "Epoch 54/70\n",
            "603/603 [==============================] - 40s 66ms/step - loss: 0.7670\n",
            "Epoch 55/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.7655\n",
            "Epoch 56/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.7599\n",
            "Epoch 57/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.7584\n",
            "Epoch 58/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.7533\n",
            "Epoch 59/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.7537\n",
            "Epoch 60/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.7496\n",
            "Epoch 61/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.7457\n",
            "Epoch 62/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.7447\n",
            "Epoch 63/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.7395\n",
            "Epoch 64/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.7381\n",
            "Epoch 65/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.7353\n",
            "Epoch 66/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.7327\n",
            "Epoch 67/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.7306\n",
            "Epoch 68/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.7281\n",
            "Epoch 69/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.7242\n",
            "Epoch 70/70\n",
            "603/603 [==============================] - 39s 65ms/step - loss: 0.7215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_buffer = input_one_hot[0]\n",
        "generated_text = input\n",
        "\n",
        "yy = []\n",
        "for i in range(100):\n",
        "    yhat = model.predict(input_buffer[None,:])\n",
        "    # sample the next character:\n",
        "    # ix = np.argmax(yhat)\n",
        "    ix = np.random.choice(range(len(chars)), p=yhat[0])\n",
        "    ch = ix_to_char[ix]\n",
        "    generated_text += ch\n",
        "    # update the input buffer:\n",
        "    input_buffer = np.r_[input_buffer[1:,:], np.zeros((1,len(chars)))]\n",
        "    input_buffer[-1,ix] = 1\n",
        "    yy.append(yhat)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "f8MmWbrojX6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb96a2e4-116e-4015-ff34-2aa517309fef"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the meaning of lifejjxqxwxatiencequely and the sigunier plansorismen looking usseliomaty and hes eurnthing  while to be\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path='/content/drive/MyDrive/ex10/russian_troll_tweets_.txt'\n",
        "# f = open('war_and_peace.txt','r') # open the corpus file\n",
        "f = open(path,'r') \n",
        "text = f.read().lower()  # read file and convert to lower-case letters\n",
        "data = text.replace('\\n','. ')\n",
        "\n",
        "# data = re.sub(r'[^a-zA-Z0-9 ]',r'',data)\n",
        "\n",
        "print('len(text) = ',len(text))\n",
        "\n",
        "print(data[:400]) # print the first 400 characters..\n",
        "\n",
        "chars = sorted(list(set(data)))\n",
        "data_size, vocab_size = len(data), len(chars)\n",
        "print('There are %d total characters and %d unique characters in your data.' % (data_size, vocab_size))\n",
        "print('chars = ',chars)\n",
        "\n",
        "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
        "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
        "\n",
        "T = 50  # extract training sequences of length T\n",
        "stride = 10\n",
        "\n",
        "sequences = []  # This holds our extracted sequences\n",
        "next_chars = []  # This holds the targets (the follow-up character)\n",
        "\n",
        "for i in range(0, len(data) - T, stride):\n",
        "    sequences.append(data[i: i + T])\n",
        "    next_chars.append(data[i + T])\n",
        "\n",
        "X = np.zeros((len(sequences), T, len(chars)), dtype='bool')\n",
        "Y = np.zeros((len(sequences), len(chars)), dtype='bool')\n",
        "\n",
        "for i, seq in enumerate(sequences):\n",
        "    for t, char in enumerate(seq):\n",
        "        X[i, t, char_to_ix[char]] = 1\n",
        "    Y[i, char_to_ix[next_chars[i]]] = 1\n",
        "\n",
        "print('X.shape = (#examples, T, input-dim) =', X.shape)\n",
        "print('Y.shape = (#examples, output-dim) =', Y.shape)"
      ],
      "metadata": {
        "id": "-btE9iMTl-wh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ebc758e-2423-404d-b942-9848e10b83af"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(text) =  754765\n",
            "the question in this election: who can put the plans into action that will make your life better? https://t.co/xreey9oicg. last night, donald trump said not paying taxes was \"smart.\" you know what i call it? unpatriotic. https://t.co/t0xmbfj7zf. couldn't be more proud of @hillaryclinton. her vision and command during last night's debate showed that she's ready to be our next @potus.. if we stand t\n",
            "There are 763212 total characters and 124 unique characters in your data.\n",
            "chars =  [' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '@', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '~', '\\xa0', '¡', '®', '¿', 'á', 'é', 'í', 'ñ', 'ó', 'ú', 'ĺ', '̶', '\\u200a', '\\u200b', '–', '—', '‘', '’', '“', '”', '•', '…', '⁰', '→', '✅', '✓', '✔', '❌', '❤', '⬇', '️', '🇸', '🇺', '🌈', '🍕', '🎓', '🎤', '🎧', '🏡', '🏻', '🏼', '🏽', '🏾', '🏿', '🐣', '👀', '👇', '👈', '👉', '👍', '👎', '👏', '👸', '👿', '💁', '💨', '💪', '📚', '🗽', '🚂', '🤔', '🤖']\n",
            "X.shape = (#examples, T, input-dim) = (76317, 50, 124)\n",
            "Y.shape = (#examples, output-dim) = (76317, 124)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_freestyle = Sequential(name='freestyle')\n",
        "model_freestyle.add(LSTM(\n",
        "        256,\n",
        "        input_shape=(X.shape[1], X.shape[2]),\n",
        "        return_sequences=True\n",
        "    ))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(LSTM(512, return_sequences=True))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(LSTM(256))\n",
        "model_freestyle.add(Dense(256))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(Dense(vocab_size))\n",
        "model_freestyle.add(Activation('softmax'))\n",
        "model_freestyle.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "model_freestyle.summary()"
      ],
      "metadata": {
        "id": "Rb9DF5eMm5ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36ca1801-e16e-4f38-d5ae-b5803771828d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"freestyle\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 50, 256)           390144    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 50, 256)           0         \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 50, 512)           1574912   \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 50, 512)           0         \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 256)               787456    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 124)               31868     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 124)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,850,172\n",
            "Trainable params: 2,850,172\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_freestyle.fit(X, Y, epochs=70, batch_size=1024)"
      ],
      "metadata": {
        "id": "VNY9fvvbm9I3",
        "outputId": "e8371769-ecd1-421c-8641-161342b3deaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "75/75 [==============================] - 15s 154ms/step - loss: 3.4187\n",
            "Epoch 2/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 3.1628\n",
            "Epoch 3/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 2.9990\n",
            "Epoch 4/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 2.6848\n",
            "Epoch 5/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 2.5110\n",
            "Epoch 6/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 2.3846\n",
            "Epoch 7/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 2.3020\n",
            "Epoch 8/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 2.2089\n",
            "Epoch 9/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 2.1303\n",
            "Epoch 10/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 2.0590\n",
            "Epoch 11/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 2.0052\n",
            "Epoch 12/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 1.9262\n",
            "Epoch 13/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 1.8785\n",
            "Epoch 14/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 1.8106\n",
            "Epoch 15/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 1.7627\n",
            "Epoch 16/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 1.7039\n",
            "Epoch 17/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 1.6541\n",
            "Epoch 18/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 1.6085\n",
            "Epoch 19/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 1.5546\n",
            "Epoch 20/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 1.5132\n",
            "Epoch 21/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 1.4631\n",
            "Epoch 22/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 1.4163\n",
            "Epoch 23/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 1.3696\n",
            "Epoch 24/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 1.3251\n",
            "Epoch 25/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 1.2751\n",
            "Epoch 26/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 1.2278\n",
            "Epoch 27/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 1.1824\n",
            "Epoch 28/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 1.1374\n",
            "Epoch 29/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 1.0907\n",
            "Epoch 30/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 1.0496\n",
            "Epoch 31/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 1.0043\n",
            "Epoch 32/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.9601\n",
            "Epoch 33/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.9224\n",
            "Epoch 34/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.8825\n",
            "Epoch 35/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.8500\n",
            "Epoch 36/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.8110\n",
            "Epoch 37/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.7804\n",
            "Epoch 38/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.7459\n",
            "Epoch 39/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.7196\n",
            "Epoch 40/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.6862\n",
            "Epoch 41/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.6617\n",
            "Epoch 42/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.6367\n",
            "Epoch 43/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.6155\n",
            "Epoch 44/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.5940\n",
            "Epoch 45/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.5734\n",
            "Epoch 46/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.5506\n",
            "Epoch 47/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.5363\n",
            "Epoch 48/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.5251\n",
            "Epoch 49/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.5031\n",
            "Epoch 50/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.4956\n",
            "Epoch 51/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.4821\n",
            "Epoch 52/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.4692\n",
            "Epoch 53/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.4551\n",
            "Epoch 54/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.4413\n",
            "Epoch 55/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.4328\n",
            "Epoch 56/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.4257\n",
            "Epoch 57/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.4199\n",
            "Epoch 58/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.4069\n",
            "Epoch 59/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.3978\n",
            "Epoch 60/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.3930\n",
            "Epoch 61/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.3812\n",
            "Epoch 62/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.3763\n",
            "Epoch 63/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.3682\n",
            "Epoch 64/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.3677\n",
            "Epoch 65/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.3564\n",
            "Epoch 66/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.3507\n",
            "Epoch 67/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.3458\n",
            "Epoch 68/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.3380\n",
            "Epoch 69/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.3323\n",
            "Epoch 70/70\n",
            "75/75 [==============================] - 12s 154ms/step - loss: 0.3265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_buffer = input_one_hot[0]\n",
        "generated_text = input\n",
        "\n",
        "yy = []\n",
        "for i in range(100):\n",
        "    yhat = model.predict(input_buffer[None,:])\n",
        "    # sample the next character:\n",
        "    # ix = np.argmax(yhat)\n",
        "    ix = np.random.choice(range(len(chars)), p=yhat[0])\n",
        "    ch = ix_to_char[ix]\n",
        "    generated_text += ch\n",
        "    # update the input buffer:\n",
        "    input_buffer = np.r_[input_buffer[1:,:], np.zeros((1,len(chars)))]\n",
        "    input_buffer[-1,ix] = 1\n",
        "    yy.append(yhat)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "uFVn38AfnHV2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "be8d784c-4ad7-4517-b58c-80140ef8c18c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-91bc2886a9a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# sample the next character:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# ix = np.argmax(yhat)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mix_to_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mgenerated_text\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 'a' and 'p' must have same size"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhpeQDqg9R_h"
      },
      "source": [
        "***\n",
        "## Good Luck!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "ex10.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}