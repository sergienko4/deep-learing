{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergienko4/deep-learing/blob/main/ex10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaMoU7zn9R_P"
      },
      "source": [
        "# Deep Learning: Ex.10 - RNN\n",
        "\n",
        "Submitted by: [... **your name and ID** ...]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oN_6bfHZ9R_S",
        "outputId": "20c807ee-eebd-454d-e0b7-afb9fbaf7e26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM # <--- recurrent layers\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from seaborn import heatmap\n",
        "import re\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path='/content/drive/MyDrive/ex10/war_and_peace.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ0BtfeM9bli",
        "outputId": "81e58933-2c4a-4d0a-9a8a-835e157b022c"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8i2f2p29R_V"
      },
      "source": [
        "***\n",
        "### 1. Preprocess the text corpus\n",
        "\n",
        "(if you are using google colab, remember to upload the corpus file first..)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L8JLzkR9R_X",
        "outputId": "2d2b9458-9fcb-4a46-85b5-35c0d77763b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(text) =  3196213\n",
            "well prince so genoa and lucca are now just family estates of the buonapartes but i warn you if you dont tell me that this means war if you still try to defend the infamies and horrors perpetrated by that antichristi really believe he is antichristi will have nothing more to do with you and you are no longer my friend no longer my faithful slave as you call yourself but how do you do i see i have \n"
          ]
        }
      ],
      "source": [
        "# f = open('war_and_peace.txt','r') # open the corpus file\n",
        "f = open(path,'r') \n",
        "text = f.read().lower()  # read file and convert to lower-case letters\n",
        "data = text.replace('\\n',' ')\n",
        "\n",
        "data = re.sub(r'[^a-zA-Z0-9 ]',r'',data)\n",
        "\n",
        "print('len(text) = ',len(text))\n",
        "\n",
        "print(data[:400]) # print the first 400 characters.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C86ydp0A9R_Y"
      },
      "source": [
        "- generate training sequences of `T=20` characters, by sampling the text corpus with a stride of 5 characters (i.e., each sequences starts 5 chars after the begining of the last sequences).\n",
        "\n",
        "- generate a matching list, holding the `next_char` for each of your sequences.\n",
        "\n",
        "- how many sequences did you extract in total? `N = ?`\n",
        "\n",
        "- convert the sequences into a 1-hot representation, suitable for our model trainig:\n",
        "\n",
        "`X.shape = (N, T, len(chars))`\n",
        "\n",
        "`Y.shape = (N, len(chars))`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(data)))\n",
        "data_size, vocab_size = len(data), len(chars)\n",
        "print('There are %d total characters and %d unique characters in your data.' % (data_size, vocab_size))\n",
        "print('chars = ',chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsmUFYMIEj43",
        "outputId": "36ad67d1-9d7f-4afb-a1dd-3d886727de77"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 3083435 total characters and 37 unique characters in your data.\n",
            "chars =  [' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
        "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
        "\n",
        "# ix_to_char"
      ],
      "metadata": {
        "id": "O7zbsDRSE8il"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T = 20  # extract training sequences of length T\n",
        "stride = 5\n",
        "\n",
        "sequences = []  # This holds our extracted sequences\n",
        "next_chars = []  # This holds the targets (the follow-up character)\n",
        "\n",
        "for i in range(0, len(data) - T, stride):\n",
        "    sequences.append(data[i: i + T])\n",
        "    next_chars.append(data[i + T])"
      ],
      "metadata": {
        "id": "9gLw2yBjFqMp"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(sequences), T, len(chars)), dtype='bool')\n",
        "Y = np.zeros((len(sequences), len(chars)), dtype='bool')\n",
        "\n",
        "for i, seq in enumerate(sequences):\n",
        "    for t, char in enumerate(seq):\n",
        "        X[i, t, char_to_ix[char]] = 1\n",
        "    Y[i, char_to_ix[next_chars[i]]] = 1\n",
        "    \n",
        "print('X.shape = (#examples, T, input-dim) =', X.shape)\n",
        "print('Y.shape = (#examples, output-dim) =', Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqQgDtlDFyHV",
        "outputId": "d62a1d44-16dd-4d2c-c484-b5fad7c2ebe4"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape = (#examples, T, input-dim) = (616683, 20, 37)\n",
            "Y.shape = (#examples, output-dim) = (616683, 37)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15DwlbpW9R_b"
      },
      "source": [
        "***\n",
        "### 2. LTSM Model\n",
        "\n",
        "- Build an `LTSM` model with 128 (hidden)-units that accepts the input sequences. Add a `Dense` layer on top of it, with `len(chars)` softmax units.\n",
        "\n",
        "- Train the model for only 1 epoch (use: `RMSprop` and batch size of 128).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential(name='LSTM_128')\n",
        "model.add(Input(shape=(T, len(chars))))  # (12,27)\n",
        "model.add(LSTM(128)) # 128 internal state units\n",
        "model.add(Dense(len(chars), activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "XH4ux8GdMazW",
        "outputId": "a9312c1b-d01b-406a-da76-9fb13570bef2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"LSTM_128\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_45 (LSTM)              (None, 128)               84992     \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 37)                4773      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 89,765\n",
            "Trainable params: 89,765\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "history = model.fit(X, Y, epochs=1, batch_size=128)"
      ],
      "metadata": {
        "id": "SVta-HkVNVD8",
        "outputId": "32f0f2e9-880a-48fc-cc4f-1855eca4e623",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4818/4818 [==============================] - 19s 4ms/step - loss: 2.0271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjfbZqIZ9R_d"
      },
      "source": [
        "### 3. Model predictions\n",
        "\n",
        "\n",
        "- use the senternce `the meaning of life ` as an input to the model (convert it to 1-hot first..),\n",
        "\n",
        "- plot the model's output as a probability distribution over the list of chars.\n",
        "\n",
        "- sample a single char from that distribution, and add it to the generated sentence.\n",
        "\n",
        "- update the 1-hot buffer, and continue the process for 99 more letters (using a loop).\n",
        "\n",
        "- print the resulting sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "QdnGKgvU9R_e"
      },
      "outputs": [],
      "source": [
        "input = 'the meaning of life'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_one_hot = np.zeros((len(input), T, len(chars)), dtype='bool')"
      ],
      "metadata": {
        "id": "p1NTrpq-OZhy"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_one_hot.shape"
      ],
      "metadata": {
        "id": "j0xk3tYdP3Yf",
        "outputId": "e965d96f-2090-4150-ff1a-98631873832b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19, 20, 37)"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = model.predict(input_one_hot)"
      ],
      "metadata": {
        "id": "4iolT6PkOqJU"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14,4))\n",
        "plt.bar(range(len(chars)), y_hat[0])\n",
        "plt.xticks(range(len(chars)), labels=chars)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LRuGNqAIPIWs",
        "outputId": "f9a97f38-1c4a-4c2a-8ea0-09b3de6a5e93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_buffer = input_one_hot[0]\n",
        "generated_text = input\n",
        "\n",
        "yy = []\n",
        "for i in range(100):\n",
        "    yhat = model.predict(input_buffer[None,:])\n",
        "    # sample the next character:\n",
        "    # ix = np.argmax(yhat)\n",
        "    ix = np.random.choice(range(len(chars)), p=yhat[0])\n",
        "    ch = ix_to_char[ix]\n",
        "    generated_text += ch\n",
        "    # update the input buffer:\n",
        "    input_buffer = np.r_[input_buffer[1:,:], np.zeros((1,len(chars)))]\n",
        "    input_buffer[-1,ix] = 1\n",
        "    yy.append(yhat)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "hLgnagExUDR0",
        "outputId": "fadbe52f-a064-460a-e226-e004097c206c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the meaning of lifeing ttrumsice befy becheed in pebiril lepreshe ang alluthousale to geerams but what mole thes wald b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uaqpz4zJ9R_f"
      },
      "source": [
        "***\n",
        "### 3. Fit your model\n",
        "\n",
        "- Fit your model a bit more (try 10-20 epochs), and regenerate a new `N=100` sentence sample. Does it get any better?\n",
        "\n",
        "- If you wish, you can try to train the model further, or you can try using a different corpus (dataset) for the training (you can even try a text in hebrew). Be creative ;)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, Y, epochs=20, batch_size=128)"
      ],
      "metadata": {
        "id": "ts6vlqWEUm5O",
        "outputId": "039d936f-a96a-4f72-97ed-deb1910a3c72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.6829\n",
            "Epoch 2/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.5883\n",
            "Epoch 3/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.5251\n",
            "Epoch 4/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.4788\n",
            "Epoch 5/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.4434\n",
            "Epoch 6/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.4150\n",
            "Epoch 7/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.3914\n",
            "Epoch 8/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.3714\n",
            "Epoch 9/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.3546\n",
            "Epoch 10/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.3394\n",
            "Epoch 11/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.3261\n",
            "Epoch 12/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.3142\n",
            "Epoch 13/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.3033\n",
            "Epoch 14/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.2936\n",
            "Epoch 15/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.2843\n",
            "Epoch 16/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.2761\n",
            "Epoch 17/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.2685\n",
            "Epoch 18/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.2617\n",
            "Epoch 19/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.2552\n",
            "Epoch 20/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.2493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nL10liRv9R_g",
        "outputId": "2eab5f93-8ed0-4ef1-d846-511717c3c851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the meaning of lifeended those whole the curters due of burden this on the evident into the bood in the backs of that o\n"
          ]
        }
      ],
      "source": [
        "input_buffer = input_one_hot[0]\n",
        "generated_text = input\n",
        "\n",
        "yy = []\n",
        "for i in range(100):\n",
        "    yhat = model.predict(input_buffer[None,:])\n",
        "    # sample the next character:\n",
        "    # ix = np.argmax(yhat)\n",
        "    ix = np.random.choice(range(len(chars)), p=yhat[0])\n",
        "    ch = ix_to_char[ix]\n",
        "    generated_text += ch\n",
        "    # update the input buffer:\n",
        "    input_buffer = np.r_[input_buffer[1:,:], np.zeros((1,len(chars)))]\n",
        "    input_buffer[-1,ix] = 1\n",
        "    yy.append(yhat)\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "wvtNTixKgW9t",
        "outputId": "83e1947d-d417-4b7e-86ad-0dfceda16f74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(616683, 20, 37)"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#---------------------------------------------------freestyle---------------------------------------------------"
      ],
      "metadata": {
        "id": "RXeWpx4utCH1"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_freestyle = Sequential(name='freestyle')\n",
        "model_freestyle.add(LSTM(\n",
        "        256,\n",
        "        input_shape=(X.shape[1], X.shape[2]),\n",
        "        return_sequences=True\n",
        "    ))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(LSTM(512, return_sequences=True))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(LSTM(256))\n",
        "model_freestyle.add(Dense(256))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(Dense(vocab_size))\n",
        "model_freestyle.add(Activation('softmax'))\n",
        "model_freestyle.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "model_freestyle.summary()\n"
      ],
      "metadata": {
        "id": "F3350UHwfT1M",
        "outputId": "29b13eb7-9afb-4c25-a6c8-e6a9293f8f83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"freestyle\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_46 (LSTM)              (None, 20, 256)           301056    \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 20, 256)           0         \n",
            "                                                                 \n",
            " lstm_47 (LSTM)              (None, 20, 512)           1574912   \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 20, 512)           0         \n",
            "                                                                 \n",
            " lstm_48 (LSTM)              (None, 256)               787456    \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 37)                9509      \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 37)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,738,725\n",
            "Trainable params: 2,738,725\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_freestyle.fit(X, Y, epochs=100, batch_size=1024)"
      ],
      "metadata": {
        "id": "uvwsS5cyhD_Y",
        "outputId": "3882236f-cb7d-45a1-eb9a-df84b6820d3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "603/603 [==============================] - 42s 64ms/step - loss: 2.3344\n",
            "Epoch 2/100\n",
            "603/603 [==============================] - 38s 64ms/step - loss: 1.7112\n",
            "Epoch 3/100\n",
            "603/603 [==============================] - 38s 64ms/step - loss: 1.4780\n",
            "Epoch 4/100\n",
            "603/603 [==============================] - 38s 64ms/step - loss: 1.3679\n",
            "Epoch 5/100\n",
            "603/603 [==============================] - 38s 64ms/step - loss: 1.3024\n",
            "Epoch 6/100\n",
            "603/603 [==============================] - 38s 64ms/step - loss: 1.2552\n",
            "Epoch 7/100\n",
            "603/603 [==============================] - 38s 64ms/step - loss: 1.2184\n",
            "Epoch 8/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 1.1879\n",
            "Epoch 9/100\n",
            "603/603 [==============================] - 38s 64ms/step - loss: 1.1624\n",
            "Epoch 10/100\n",
            "603/603 [==============================] - 38s 64ms/step - loss: 1.1384\n",
            "Epoch 11/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 1.1166\n",
            "Epoch 12/100\n",
            "603/603 [==============================] - 38s 64ms/step - loss: 1.0969\n",
            "Epoch 13/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 1.0773\n",
            "Epoch 14/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 1.0598\n",
            "Epoch 15/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 1.0438\n",
            "Epoch 16/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 1.0268\n",
            "Epoch 17/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 1.0124\n",
            "Epoch 18/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.9984\n",
            "Epoch 19/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.9841\n",
            "Epoch 20/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.9723\n",
            "Epoch 21/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.9609\n",
            "Epoch 22/100\n",
            "603/603 [==============================] - 38s 64ms/step - loss: 0.9491\n",
            "Epoch 23/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.9383\n",
            "Epoch 24/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.9273\n",
            "Epoch 25/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.9174\n",
            "Epoch 26/100\n",
            "603/603 [==============================] - 38s 64ms/step - loss: 0.9092\n",
            "Epoch 27/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.8999\n",
            "Epoch 28/100\n",
            "603/603 [==============================] - 38s 64ms/step - loss: 0.8924\n",
            "Epoch 29/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.8832\n",
            "Epoch 30/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.8760\n",
            "Epoch 31/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.8688\n",
            "Epoch 32/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.8613\n",
            "Epoch 33/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.8568\n",
            "Epoch 34/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.8487\n",
            "Epoch 35/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.8433\n",
            "Epoch 36/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.8382\n",
            "Epoch 37/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.8298\n",
            "Epoch 38/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.8267\n",
            "Epoch 39/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.8214\n",
            "Epoch 40/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.8150\n",
            "Epoch 41/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.8130\n",
            "Epoch 42/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.8055\n",
            "Epoch 43/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.8036\n",
            "Epoch 44/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7984\n",
            "Epoch 45/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7929\n",
            "Epoch 46/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7907\n",
            "Epoch 47/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7846\n",
            "Epoch 48/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7819\n",
            "Epoch 49/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7778\n",
            "Epoch 50/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7738\n",
            "Epoch 51/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7688\n",
            "Epoch 52/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7673\n",
            "Epoch 53/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7646\n",
            "Epoch 54/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7597\n",
            "Epoch 55/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7556\n",
            "Epoch 56/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7548\n",
            "Epoch 57/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7492\n",
            "Epoch 58/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7471\n",
            "Epoch 59/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7439\n",
            "Epoch 60/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7404\n",
            "Epoch 61/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7365\n",
            "Epoch 62/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7335\n",
            "Epoch 63/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7312\n",
            "Epoch 64/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7295\n",
            "Epoch 65/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7242\n",
            "Epoch 66/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7230\n",
            "Epoch 67/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7209\n",
            "Epoch 68/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7178\n",
            "Epoch 69/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7147\n",
            "Epoch 70/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7107\n",
            "Epoch 71/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7097\n",
            "Epoch 72/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7073\n",
            "Epoch 73/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7046\n",
            "Epoch 74/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.7005\n",
            "Epoch 75/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6990\n",
            "Epoch 76/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6967\n",
            "Epoch 77/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6937\n",
            "Epoch 78/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6905\n",
            "Epoch 79/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6899\n",
            "Epoch 80/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6865\n",
            "Epoch 81/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6836\n",
            "Epoch 82/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6815\n",
            "Epoch 83/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6793\n",
            "Epoch 84/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6774\n",
            "Epoch 85/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6762\n",
            "Epoch 86/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6723\n",
            "Epoch 87/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6704\n",
            "Epoch 88/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6681\n",
            "Epoch 89/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6672\n",
            "Epoch 90/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6644\n",
            "Epoch 91/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6632\n",
            "Epoch 92/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6603\n",
            "Epoch 93/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6564\n",
            "Epoch 94/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6553\n",
            "Epoch 95/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6539\n",
            "Epoch 96/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6506\n",
            "Epoch 97/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6482\n",
            "Epoch 98/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6471\n",
            "Epoch 99/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6457\n",
            "Epoch 100/100\n",
            "603/603 [==============================] - 39s 64ms/step - loss: 0.6428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_buffer = input_one_hot[0]\n",
        "generated_text = input\n",
        "\n",
        "yy = []\n",
        "for i in range(100):\n",
        "    yhat = model.predict(input_buffer[None,:])\n",
        "    # sample the next character:\n",
        "    # ix = np.argmax(yhat)\n",
        "    ix = np.random.choice(range(len(chars)), p=yhat[0])\n",
        "    ch = ix_to_char[ix]\n",
        "    generated_text += ch\n",
        "    # update the input buffer:\n",
        "    input_buffer = np.r_[input_buffer[1:,:], np.zeros((1,len(chars)))]\n",
        "    input_buffer[-1,ix] = 1\n",
        "    yy.append(yhat)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "f8MmWbrojX6E",
        "outputId": "759b25e1-7f24-4c9a-d06e-dc439f2e8e32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the meaning of lifefacely as hose he had outside was been caulled no one thing is convinced an aychaughts of its arms o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path='/content/drive/MyDrive/ex10/russian_troll_tweets_.txt'\n",
        "# f = open('war_and_peace.txt','r') # open the corpus file\n",
        "f = open(path,'r') \n",
        "text = f.read().lower()  # read file and convert to lower-case letters\n",
        "data = text.replace('\\n','.')\n",
        "\n",
        "# data = re.sub(r'[^a-zA-Z0-9 ]',r'',data)\n",
        "\n",
        "print('len(text) = ',len(text))\n",
        "\n",
        "print(data[:400]) # print the first 400 characters..\n",
        "\n",
        "chars = sorted(list(set(data)))\n",
        "data_size, vocab_size = len(data), len(chars)\n",
        "print('There are %d total characters and %d unique characters in your data.' % (data_size, vocab_size))\n",
        "print('chars = ',chars)\n",
        "\n",
        "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
        "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
        "\n",
        "T = 50  # extract training sequences of length T\n",
        "stride = 10\n",
        "\n",
        "sequences = []  # This holds our extracted sequences\n",
        "next_chars = []  # This holds the targets (the follow-up character)\n",
        "\n",
        "for i in range(0, len(data) - T, stride):\n",
        "    sequences.append(data[i: i + T])\n",
        "    next_chars.append(data[i + T])\n",
        "\n",
        "X = np.zeros((len(sequences), T, len(chars)), dtype='bool')\n",
        "Y = np.zeros((len(sequences), len(chars)), dtype='bool')\n",
        "\n",
        "for i, seq in enumerate(sequences):\n",
        "    for t, char in enumerate(seq):\n",
        "        X[i, t, char_to_ix[char]] = 1\n",
        "    Y[i, char_to_ix[next_chars[i]]] = 1\n",
        "\n",
        "print('X.shape = (#examples, T, input-dim) =', X.shape)\n",
        "print('Y.shape = (#examples, output-dim) =', Y.shape)"
      ],
      "metadata": {
        "id": "-btE9iMTl-wh",
        "outputId": "ab7448f8-02e8-4fac-fb8a-709894b9107e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(text) =  754765\n",
            "the question in this election: who can put the plans into action that will make your life better? https://t.co/xreey9oicg.last night, donald trump said not paying taxes was \"smart.\" you know what i call it? unpatriotic. https://t.co/t0xmbfj7zf.couldn't be more proud of @hillaryclinton. her vision and command during last night's debate showed that she's ready to be our next @potus..if we stand toge\n",
            "There are 754765 total characters and 124 unique characters in your data.\n",
            "chars =  [' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '@', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '~', '\\xa0', '¬°', '¬Æ', '¬ø', '√°', '√©', '√≠', '√±', '√≥', '√∫', 'ƒ∫', 'Ã∂', '\\u200a', '\\u200b', '‚Äì', '‚Äî', '‚Äò', '‚Äô', '‚Äú', '‚Äù', '‚Ä¢', '‚Ä¶', '‚Å∞', '‚Üí', '‚úÖ', '‚úì', '‚úî', '‚ùå', '‚ù§', '‚¨á', 'Ô∏è', 'üá∏', 'üá∫', 'üåà', 'üçï', 'üéì', 'üé§', 'üéß', 'üè°', 'üèª', 'üèº', 'üèΩ', 'üèæ', 'üèø', 'üê£', 'üëÄ', 'üëá', 'üëà', 'üëâ', 'üëç', 'üëé', 'üëè', 'üë∏', 'üëø', 'üíÅ', 'üí®', 'üí™', 'üìö', 'üóΩ', 'üöÇ', 'ü§î', 'ü§ñ']\n",
            "X.shape = (#examples, T, input-dim) = (75472, 50, 124)\n",
            "Y.shape = (#examples, output-dim) = (75472, 124)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_freestyle = Sequential(name='freestyle')\n",
        "model_freestyle.add(LSTM(\n",
        "        256,\n",
        "        input_shape=(X.shape[1], X.shape[2]),\n",
        "        return_sequences=True\n",
        "    ))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(LSTM(512, return_sequences=True))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(LSTM(256))\n",
        "model_freestyle.add(Dense(256))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(Dense(vocab_size))\n",
        "model_freestyle.add(Activation('softmax'))\n",
        "model_freestyle.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "model_freestyle.summary()"
      ],
      "metadata": {
        "id": "Rb9DF5eMm5ec",
        "outputId": "f273f2f4-145f-496f-ef7c-2bd334407043",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"freestyle\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_49 (LSTM)              (None, 50, 256)           390144    \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 50, 256)           0         \n",
            "                                                                 \n",
            " lstm_50 (LSTM)              (None, 50, 512)           1574912   \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 50, 512)           0         \n",
            "                                                                 \n",
            " lstm_51 (LSTM)              (None, 256)               787456    \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 124)               31868     \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 124)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,850,172\n",
            "Trainable params: 2,850,172\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_freestyle.fit(X, Y, epochs=50, batch_size=1024)"
      ],
      "metadata": {
        "id": "VNY9fvvbm9I3",
        "outputId": "2110b4d5-9cee-45bb-cc98-75328df3e054",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "74/74 [==============================] - 15s 154ms/step - loss: 3.4151\n",
            "Epoch 2/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 3.1748\n",
            "Epoch 3/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 3.0785\n",
            "Epoch 4/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 3.0117\n",
            "Epoch 5/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 2.7473\n",
            "Epoch 6/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 2.5732\n",
            "Epoch 7/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 2.4562\n",
            "Epoch 8/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 2.3475\n",
            "Epoch 9/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 2.2507\n",
            "Epoch 10/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 2.1710\n",
            "Epoch 11/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 2.0903\n",
            "Epoch 12/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 2.0143\n",
            "Epoch 13/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 1.9436\n",
            "Epoch 14/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 1.8821\n",
            "Epoch 15/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 1.8179\n",
            "Epoch 16/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 1.7571\n",
            "Epoch 17/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 1.7018\n",
            "Epoch 18/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 1.6526\n",
            "Epoch 19/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 1.5932\n",
            "Epoch 20/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 1.5456\n",
            "Epoch 21/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 1.4928\n",
            "Epoch 22/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 1.4424\n",
            "Epoch 23/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 1.3849\n",
            "Epoch 24/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 1.3393\n",
            "Epoch 25/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 1.2872\n",
            "Epoch 26/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 1.2363\n",
            "Epoch 27/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 1.1851\n",
            "Epoch 28/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 1.1435\n",
            "Epoch 29/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 1.0860\n",
            "Epoch 30/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 1.0451\n",
            "Epoch 31/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 0.9946\n",
            "Epoch 32/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 0.9516\n",
            "Epoch 33/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 0.9030\n",
            "Epoch 34/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 0.8631\n",
            "Epoch 35/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 0.8183\n",
            "Epoch 36/50\n",
            "74/74 [==============================] - 11s 154ms/step - loss: 0.7887\n",
            "Epoch 37/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 0.7514\n",
            "Epoch 38/50\n",
            "74/74 [==============================] - 11s 154ms/step - loss: 0.7143\n",
            "Epoch 39/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 0.6918\n",
            "Epoch 40/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 0.6651\n",
            "Epoch 41/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 0.6347\n",
            "Epoch 42/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 0.6169\n",
            "Epoch 43/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 0.5873\n",
            "Epoch 44/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 0.5690\n",
            "Epoch 45/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 0.5500\n",
            "Epoch 46/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 0.5325\n",
            "Epoch 47/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 0.5082\n",
            "Epoch 48/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 0.4981\n",
            "Epoch 49/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 0.4798\n",
            "Epoch 50/50\n",
            "74/74 [==============================] - 11s 155ms/step - loss: 0.4666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_buffer = input_one_hot[0]\n",
        "generated_text = input\n",
        "\n",
        "yy = []\n",
        "for i in range(200):\n",
        "    yhat = model.predict(input_buffer[None,:])\n",
        "    # sample the next character:\n",
        "    # ix = np.argmax(yhat)\n",
        "    ix = np.random.choice(range(len(chars)), p=yhat[0])\n",
        "    ch = ix_to_char[ix]\n",
        "    generated_text += ch\n",
        "    # update the input buffer:\n",
        "    input_buffer = np.r_[input_buffer[1:,:], np.zeros((1,len(chars)))]\n",
        "    input_buffer[-1,ix] = 1\n",
        "    yy.append(yhat)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "uFVn38AfnHV2",
        "outputId": "13c00ab0-34fa-4764-c428-d6ae62c9de05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-182-5bd865e354e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# sample the next character:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# ix = np.argmax(yhat)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mix_to_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mgenerated_text\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 'a' and 'p' must have same size"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhpeQDqg9R_h"
      },
      "source": [
        "***\n",
        "## Good Luck!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "ex10.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}