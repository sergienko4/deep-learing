{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergienko4/deep-learing/blob/main/ex10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaMoU7zn9R_P"
      },
      "source": [
        "# Deep Learning: Ex.10 - RNN\n",
        "\n",
        "Submitted by: [... **your name and ID** ...]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oN_6bfHZ9R_S",
        "outputId": "27abfad1-3ba7-4b5a-b60c-b7377c44b72b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM # <--- recurrent layers\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from seaborn import heatmap\n",
        "import re\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path='/content/drive/MyDrive/ex10/war_and_peace.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ0BtfeM9bli",
        "outputId": "91243fc0-6590-4969-8b80-380a7f7a3a76"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8i2f2p29R_V"
      },
      "source": [
        "***\n",
        "### 1. Preprocess the text corpus\n",
        "\n",
        "(if you are using google colab, remember to upload the corpus file first..)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L8JLzkR9R_X",
        "outputId": "e17ddef0-d0ba-4ba7-9ae9-42232b78ba2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(text) =  3196213\n",
            "well prince so genoa and lucca are now just family estates of the buonapartes but i warn you if you dont tell me that this means war if you still try to defend the infamies and horrors perpetrated by that antichristi really believe he is antichristi will have nothing more to do with you and you are no longer my friend no longer my faithful slave as you call yourself but how do you do i see i have \n"
          ]
        }
      ],
      "source": [
        "# f = open('war_and_peace.txt','r') # open the corpus file\n",
        "f = open(path,'r') \n",
        "text = f.read().lower()  # read file and convert to lower-case letters\n",
        "data = text.replace('\\n',' ')\n",
        "\n",
        "data = re.sub(r'[^a-zA-Z0-9 ]',r'',data)\n",
        "\n",
        "print('len(text) = ',len(text))\n",
        "\n",
        "print(data[:400]) # print the first 400 characters.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C86ydp0A9R_Y"
      },
      "source": [
        "- generate training sequences of `T=20` characters, by sampling the text corpus with a stride of 5 characters (i.e., each sequences starts 5 chars after the begining of the last sequences).\n",
        "\n",
        "- generate a matching list, holding the `next_char` for each of your sequences.\n",
        "\n",
        "- how many sequences did you extract in total? `N = ?`\n",
        "\n",
        "- convert the sequences into a 1-hot representation, suitable for our model trainig:\n",
        "\n",
        "`X.shape = (N, T, len(chars))`\n",
        "\n",
        "`Y.shape = (N, len(chars))`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(data)))\n",
        "data_size, vocab_size = len(data), len(chars)\n",
        "print('There are %d total characters and %d unique characters in your data.' % (data_size, vocab_size))\n",
        "print('chars = ',chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsmUFYMIEj43",
        "outputId": "f27ad48d-3289-4491-a246-12cef84528ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 3083435 total characters and 37 unique characters in your data.\n",
            "chars =  [' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
        "ix_to_char = { i:ch for i,ch in enumerate(chars) }"
      ],
      "metadata": {
        "id": "O7zbsDRSE8il"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T = 20  # extract training sequences of length T\n",
        "stride = 5\n",
        "\n",
        "sequences = []  # This holds our extracted sequences\n",
        "next_chars = []  # This holds the targets (the follow-up character)\n",
        "\n",
        "for i in range(0, len(data) - T, stride):\n",
        "    sequences.append(data[i: i + T])\n",
        "    next_chars.append(data[i + T])"
      ],
      "metadata": {
        "id": "9gLw2yBjFqMp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(sequences), T, len(chars)), dtype='bool')\n",
        "Y = np.zeros((len(sequences), len(chars)), dtype='bool')\n",
        "\n",
        "for i, seq in enumerate(sequences):\n",
        "    for t, char in enumerate(seq):\n",
        "        X[i, t, char_to_ix[char]] = 1\n",
        "    Y[i, char_to_ix[next_chars[i]]] = 1\n",
        "    \n",
        "print('X.shape = (#examples, T, input-dim) =', X.shape)\n",
        "print('Y.shape = (#examples, output-dim) =', Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqQgDtlDFyHV",
        "outputId": "a398cb31-02bd-44fa-87ac-2f5c06b0b24a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape = (#examples, T, input-dim) = (616683, 20, 37)\n",
            "Y.shape = (#examples, output-dim) = (616683, 37)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15DwlbpW9R_b"
      },
      "source": [
        "***\n",
        "### 2. LTSM Model\n",
        "\n",
        "- Build an `LTSM` model with 128 (hidden)-units that accepts the input sequences. Add a `Dense` layer on top of it, with `len(chars)` softmax units.\n",
        "\n",
        "- Train the model for only 1 epoch (use: `RMSprop` and batch size of 128).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential(name='LSTM_128')\n",
        "model.add(Input(shape=(T, len(chars))))  # (12,27)\n",
        "model.add(LSTM(128)) # 128 internal state units\n",
        "model.add(Dense(len(chars), activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "XH4ux8GdMazW",
        "outputId": "b3de10a0-61ed-4492-af5e-9ca422312ce3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"LSTM_128\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128)               84992     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 37)                4773      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 89,765\n",
            "Trainable params: 89,765\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "history = model.fit(X, Y, epochs=1, batch_size=128)"
      ],
      "metadata": {
        "id": "SVta-HkVNVD8",
        "outputId": "dc180d41-740c-43eb-e0bf-9b2877b027c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4818/4818 [==============================] - 22s 4ms/step - loss: 2.0316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjfbZqIZ9R_d"
      },
      "source": [
        "### 3. Model predictions\n",
        "\n",
        "\n",
        "- use the senternce `the meaning of life ` as an input to the model (convert it to 1-hot first..),\n",
        "\n",
        "- plot the model's output as a probability distribution over the list of chars.\n",
        "\n",
        "- sample a single char from that distribution, and add it to the generated sentence.\n",
        "\n",
        "- update the 1-hot buffer, and continue the process for 99 more letters (using a loop).\n",
        "\n",
        "- print the resulting sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QdnGKgvU9R_e"
      },
      "outputs": [],
      "source": [
        "input = 'the meaning of life'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_one_hot = np.zeros((len(input), T, len(chars)), dtype='bool')"
      ],
      "metadata": {
        "id": "p1NTrpq-OZhy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_one_hot.shape"
      ],
      "metadata": {
        "id": "j0xk3tYdP3Yf",
        "outputId": "199302c0-93f3-4906-a507-5f2d3c44b247",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19, 20, 37)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = model.predict(input_one_hot)"
      ],
      "metadata": {
        "id": "4iolT6PkOqJU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14,4))\n",
        "plt.bar(range(len(chars)), y_hat[0])\n",
        "plt.xticks(range(len(chars)), labels=chars)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LRuGNqAIPIWs",
        "outputId": "f003da77-5686-4afb-b3d6-669ffccaf5f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_buffer = input_one_hot[0]\n",
        "generated_text = input\n",
        "\n",
        "yy = []\n",
        "for i in range(100):\n",
        "    yhat = model.predict(input_buffer[None,:])\n",
        "    # sample the next character:\n",
        "    # ix = np.argmax(yhat)\n",
        "    ix = np.random.choice(range(len(chars)), p=yhat[0])\n",
        "    ch = ix_to_char[ix]\n",
        "    generated_text += ch\n",
        "    # update the input buffer:\n",
        "    input_buffer = np.r_[input_buffer[1:,:], np.zeros((1,len(chars)))]\n",
        "    input_buffer[-1,ix] = 1\n",
        "    yy.append(yhat)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "hLgnagExUDR0",
        "outputId": "f5897ebd-023e-416c-e3fd-e3db85b746c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the meaning of lifes whies he pessed fortentan exclingitlant the sall om to the comane stound them turet ta ht and all \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uaqpz4zJ9R_f"
      },
      "source": [
        "***\n",
        "### 3. Fit your model\n",
        "\n",
        "- Fit your model a bit more (try 10-20 epochs), and regenerate a new `N=100` sentence sample. Does it get any better?\n",
        "\n",
        "- If you wish, you can try to train the model further, or you can try using a different corpus (dataset) for the training (you can even try a text in hebrew). Be creative ;)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, Y, epochs=20, batch_size=128)"
      ],
      "metadata": {
        "id": "ts6vlqWEUm5O",
        "outputId": "4c964193-6178-4a0b-9983-9338a072afc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.6541\n",
            "Epoch 2/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.5229\n",
            "Epoch 3/20\n",
            "4818/4818 [==============================] - 20s 4ms/step - loss: 1.4498\n",
            "Epoch 4/20\n",
            "4818/4818 [==============================] - 19s 4ms/step - loss: 1.4016\n",
            "Epoch 5/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.3670\n",
            "Epoch 6/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.3401\n",
            "Epoch 7/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.3190\n",
            "Epoch 8/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.3016\n",
            "Epoch 9/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.2872\n",
            "Epoch 10/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.2751\n",
            "Epoch 11/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.2642\n",
            "Epoch 12/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.2553\n",
            "Epoch 13/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.2465\n",
            "Epoch 14/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.2394\n",
            "Epoch 15/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.2327\n",
            "Epoch 16/20\n",
            "4818/4818 [==============================] - 19s 4ms/step - loss: 1.2268\n",
            "Epoch 17/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.2210\n",
            "Epoch 18/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.2158\n",
            "Epoch 19/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.2114\n",
            "Epoch 20/20\n",
            "4818/4818 [==============================] - 18s 4ms/step - loss: 1.2070\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nL10liRv9R_g",
        "outputId": "36ffda64-f593-45c0-c9cc-4b4bc13261d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the meaning of lifeqqxjjjykxqxxxxitifless of god was most day coming rose and activation without eath toward beside on \n"
          ]
        }
      ],
      "source": [
        "input_buffer = input_one_hot[0]\n",
        "generated_text = input\n",
        "\n",
        "yy = []\n",
        "for i in range(100):\n",
        "    yhat = model.predict(input_buffer[None,:])\n",
        "    # sample the next character:\n",
        "    # ix = np.argmax(yhat)\n",
        "    ix = np.random.choice(range(len(chars)), p=yhat[0])\n",
        "    ch = ix_to_char[ix]\n",
        "    generated_text += ch\n",
        "    # update the input buffer:\n",
        "    input_buffer = np.r_[input_buffer[1:,:], np.zeros((1,len(chars)))]\n",
        "    input_buffer[-1,ix] = 1\n",
        "    yy.append(yhat)\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#---------------------------------------------------freestyle---------------------------------------------------"
      ],
      "metadata": {
        "id": "RXeWpx4utCH1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_freestyle = Sequential(name='freestyle')\n",
        "model_freestyle.add(LSTM(\n",
        "        256,\n",
        "        input_shape=(X.shape[1], X.shape[2]),\n",
        "        return_sequences=True\n",
        "    ))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(LSTM(512, return_sequences=True))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(LSTM(256))\n",
        "model_freestyle.add(Dense(256))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(Dense(vocab_size))\n",
        "model_freestyle.add(Activation('softmax'))\n",
        "model_freestyle.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "model_freestyle.summary()\n"
      ],
      "metadata": {
        "id": "F3350UHwfT1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d81667d-3a7d-4bbb-cae3-153975bd0ed3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"freestyle\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 20, 256)           301056    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 20, 256)           0         \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 20, 512)           1574912   \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 20, 512)           0         \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 256)               787456    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 37)                9509      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 37)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,738,725\n",
            "Trainable params: 2,738,725\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_freestyle.fit(X, Y, epochs=50, batch_size=70)"
      ],
      "metadata": {
        "id": "uvwsS5cyhD_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c443d9ad-d95c-487c-bf6c-3776d5f1be8c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "8810/8810 [==============================] - 121s 13ms/step - loss: 1.8061\n",
            "Epoch 2/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 1.4056\n",
            "Epoch 3/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 1.3170\n",
            "Epoch 4/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 1.2733\n",
            "Epoch 5/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 1.2445\n",
            "Epoch 6/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 1.2226\n",
            "Epoch 7/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 1.2043\n",
            "Epoch 8/50\n",
            "8810/8810 [==============================] - 117s 13ms/step - loss: 1.1906\n",
            "Epoch 9/50\n",
            "8810/8810 [==============================] - 117s 13ms/step - loss: 1.1783\n",
            "Epoch 10/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 1.1668\n",
            "Epoch 11/50\n",
            "8810/8810 [==============================] - 117s 13ms/step - loss: 1.1575\n",
            "Epoch 12/50\n",
            "8810/8810 [==============================] - 115s 13ms/step - loss: 1.1469\n",
            "Epoch 13/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 1.1388\n",
            "Epoch 14/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 1.1307\n",
            "Epoch 15/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 1.1221\n",
            "Epoch 16/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 1.1148\n",
            "Epoch 17/50\n",
            "8810/8810 [==============================] - 117s 13ms/step - loss: 1.1072\n",
            "Epoch 18/50\n",
            "8810/8810 [==============================] - 117s 13ms/step - loss: 1.1010\n",
            "Epoch 19/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 1.0937\n",
            "Epoch 20/50\n",
            "8810/8810 [==============================] - 117s 13ms/step - loss: 1.0860\n",
            "Epoch 21/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 1.0801\n",
            "Epoch 22/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 1.0729\n",
            "Epoch 23/50\n",
            "8810/8810 [==============================] - 117s 13ms/step - loss: 1.0663\n",
            "Epoch 24/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 1.0601\n",
            "Epoch 25/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 1.0538\n",
            "Epoch 26/50\n",
            "8810/8810 [==============================] - 117s 13ms/step - loss: 1.0488\n",
            "Epoch 27/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 1.0430\n",
            "Epoch 28/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 1.0362\n",
            "Epoch 29/50\n",
            "8810/8810 [==============================] - 117s 13ms/step - loss: 1.0306\n",
            "Epoch 30/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 1.0244\n",
            "Epoch 31/50\n",
            "8810/8810 [==============================] - 115s 13ms/step - loss: 1.0177\n",
            "Epoch 32/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 1.0124\n",
            "Epoch 33/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 1.0074\n",
            "Epoch 34/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 1.0014\n",
            "Epoch 35/50\n",
            "8810/8810 [==============================] - 117s 13ms/step - loss: 0.9966\n",
            "Epoch 36/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 0.9914\n",
            "Epoch 37/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 0.9844\n",
            "Epoch 38/50\n",
            "8810/8810 [==============================] - 117s 13ms/step - loss: 0.9792\n",
            "Epoch 39/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 0.9752\n",
            "Epoch 40/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 0.9694\n",
            "Epoch 41/50\n",
            "8810/8810 [==============================] - 117s 13ms/step - loss: 0.9640\n",
            "Epoch 42/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 0.9596\n",
            "Epoch 43/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 0.9551\n",
            "Epoch 44/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 0.9515\n",
            "Epoch 45/50\n",
            "8810/8810 [==============================] - 117s 13ms/step - loss: 0.9449\n",
            "Epoch 46/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 0.9401\n",
            "Epoch 47/50\n",
            "8810/8810 [==============================] - 117s 13ms/step - loss: 0.9364\n",
            "Epoch 48/50\n",
            "8810/8810 [==============================] - 117s 13ms/step - loss: 0.9318\n",
            "Epoch 49/50\n",
            "8810/8810 [==============================] - 116s 13ms/step - loss: 0.9270\n",
            "Epoch 50/50\n",
            "8810/8810 [==============================] - 117s 13ms/step - loss: 0.9218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_buffer = input_one_hot[0]\n",
        "generated_text = input\n",
        "\n",
        "yy = []\n",
        "for i in range(100):\n",
        "    yhat = model.predict(input_buffer[None,:])\n",
        "    # sample the next character:\n",
        "    # ix = np.argmax(yhat)\n",
        "    ix = np.random.choice(range(len(chars)), p=yhat[0])\n",
        "    ch = ix_to_char[ix]\n",
        "    generated_text += ch\n",
        "    # update the input buffer:\n",
        "    input_buffer = np.r_[input_buffer[1:,:], np.zeros((1,len(chars)))]\n",
        "    input_buffer[-1,ix] = 1\n",
        "    yy.append(yhat)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "f8MmWbrojX6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2965e15a-fb35-4061-dbb8-0cbd56e63232"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the meaning of lifeqjzqqqjqqxxxxxhersy and tractle miserisary could say you are yes it you see pierre had been betting \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path='/content/drive/MyDrive/ex10/russian_troll_tweets_.txt'\n",
        "# f = open('war_and_peace.txt','r') # open the corpus file\n",
        "f = open(path,'r') \n",
        "text = f.read().lower()  # read file and convert to lower-case letters\n",
        "data = text.replace('\\n','.')\n",
        "data = re.sub(r'[^a-zA-Z0-9 ]',r'',data)\n",
        "\n",
        "\n",
        "\n",
        "# data = re.sub(r'[^a-zA-Z0-9 ]',r'',data)\n",
        "\n",
        "print('len(text) = ',len(data))\n",
        "\n",
        "print(data[:400]) # print the first 400 characters..\n",
        "\n",
        "chars = sorted(list(set(data)))\n",
        "data_size, vocab_size = len(data), len(chars)\n",
        "print('There are %d total characters and %d unique characters in your data.' % (data_size, vocab_size))\n",
        "print('chars = ',chars)\n",
        "\n",
        "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
        "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
        "\n",
        "T = 50  # extract training sequences of length T\n",
        "stride = 10\n",
        "\n",
        "sequences = []  # This holds our extracted sequences\n",
        "next_chars = []  # This holds the targets (the follow-up character)\n",
        "\n",
        "for i in range(0, len(data) - T, stride):\n",
        "    sequences.append(data[i: i + T])\n",
        "    next_chars.append(data[i + T])\n",
        "\n",
        "X = np.zeros((len(sequences), T, len(chars)), dtype='bool')\n",
        "Y = np.zeros((len(sequences), len(chars)), dtype='bool')\n",
        "\n",
        "for i, seq in enumerate(sequences):\n",
        "    for t, char in enumerate(seq):\n",
        "        X[i, t, char_to_ix[char]] = 1\n",
        "    Y[i, char_to_ix[next_chars[i]]] = 1\n",
        "\n",
        "print('X.shape = (#examples, T, input-dim) =', X.shape)\n",
        "print('Y.shape = (#examples, output-dim) =', Y.shape)"
      ],
      "metadata": {
        "id": "-btE9iMTl-wh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d34b2b9-4547-4652-8946-cc763cf0cd7f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(text) =  694050\n",
            "the question in this election who can put the plans into action that will make your life better httpstcoxreey9oicglast night donald trump said not paying taxes was smart you know what i call it unpatriotic httpstcot0xmbfj7zfcouldnt be more proud of hillaryclinton her vision and command during last nights debate showed that shes ready to be our next potusif we stand together theres nothing we cant \n",
            "There are 694050 total characters and 37 unique characters in your data.\n",
            "chars =  [' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "X.shape = (#examples, T, input-dim) = (69400, 50, 37)\n",
            "Y.shape = (#examples, output-dim) = (69400, 37)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_freestyle = Sequential(name='freestyle')\n",
        "model_freestyle.add(LSTM(\n",
        "        256,\n",
        "        input_shape=(X.shape[1], X.shape[2]),\n",
        "        return_sequences=True\n",
        "    ))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(LSTM(512, return_sequences=True))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(LSTM(256))\n",
        "model_freestyle.add(Dense(256))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(Dense(vocab_size))\n",
        "model_freestyle.add(Activation('softmax'))\n",
        "model_freestyle.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "model_freestyle.summary()"
      ],
      "metadata": {
        "id": "Rb9DF5eMm5ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6af5e33f-a95b-43d5-8417-046c3e7561d0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"freestyle\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 50, 256)           301056    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 50, 256)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 50, 512)           1574912   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 50, 512)           0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 256)               787456    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 37)                9509      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 37)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,738,725\n",
            "Trainable params: 2,738,725\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_freestyle.fit(X, Y, epochs=50, batch_size=70)"
      ],
      "metadata": {
        "id": "VNY9fvvbm9I3",
        "outputId": "bb78b492-d6f8-4782-a63c-94b2ad54896f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "992/992 [==============================] - 31s 27ms/step - loss: 2.8952\n",
            "Epoch 2/50\n",
            "992/992 [==============================] - 27s 27ms/step - loss: 2.4361\n",
            "Epoch 3/50\n",
            "992/992 [==============================] - 27s 27ms/step - loss: 2.3597\n",
            "Epoch 4/50\n",
            "992/992 [==============================] - 27s 27ms/step - loss: 2.2399\n",
            "Epoch 5/50\n",
            "992/992 [==============================] - 27s 27ms/step - loss: 2.0040\n",
            "Epoch 6/50\n",
            "992/992 [==============================] - 27s 27ms/step - loss: 1.8818\n",
            "Epoch 7/50\n",
            "992/992 [==============================] - 27s 27ms/step - loss: 1.7957\n",
            "Epoch 8/50\n",
            "992/992 [==============================] - 26s 27ms/step - loss: 1.7190\n",
            "Epoch 9/50\n",
            "992/992 [==============================] - 26s 27ms/step - loss: 1.6539\n",
            "Epoch 10/50\n",
            "992/992 [==============================] - 27s 27ms/step - loss: 1.5918\n",
            "Epoch 11/50\n",
            "992/992 [==============================] - 27s 27ms/step - loss: 1.5343\n",
            "Epoch 12/50\n",
            "992/992 [==============================] - 27s 27ms/step - loss: 1.4804\n",
            "Epoch 13/50\n",
            "992/992 [==============================] - 27s 27ms/step - loss: 1.4282\n",
            "Epoch 14/50\n",
            "992/992 [==============================] - 27s 27ms/step - loss: 1.3764\n",
            "Epoch 15/50\n",
            "992/992 [==============================] - 27s 27ms/step - loss: 1.3240\n",
            "Epoch 16/50\n",
            "992/992 [==============================] - 27s 27ms/step - loss: 1.2758\n",
            "Epoch 17/50\n",
            "992/992 [==============================] - 27s 27ms/step - loss: 1.2336\n",
            "Epoch 18/50\n",
            "992/992 [==============================] - 27s 27ms/step - loss: 1.1874\n",
            "Epoch 19/50\n",
            "992/992 [==============================] - 27s 27ms/step - loss: 1.1436\n",
            "Epoch 20/50\n",
            "992/992 [==============================] - 27s 27ms/step - loss: 1.1092\n",
            "Epoch 21/50\n",
            "992/992 [==============================] - 27s 27ms/step - loss: 1.0745\n",
            "Epoch 22/50\n",
            "992/992 [==============================] - 26s 27ms/step - loss: 1.0364\n",
            "Epoch 23/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 1.0057\n",
            "Epoch 24/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.9746\n",
            "Epoch 25/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.9433\n",
            "Epoch 26/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.9169\n",
            "Epoch 27/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.8987\n",
            "Epoch 28/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.8770\n",
            "Epoch 29/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.8542\n",
            "Epoch 30/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.8246\n",
            "Epoch 31/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.8092\n",
            "Epoch 32/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.7910\n",
            "Epoch 33/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.7835\n",
            "Epoch 34/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.7595\n",
            "Epoch 35/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.7513\n",
            "Epoch 36/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.7317\n",
            "Epoch 37/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.7195\n",
            "Epoch 38/50\n",
            "992/992 [==============================] - 26s 27ms/step - loss: 0.7143\n",
            "Epoch 39/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.6997\n",
            "Epoch 40/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.6931\n",
            "Epoch 41/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.6832\n",
            "Epoch 42/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.6763\n",
            "Epoch 43/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.6679\n",
            "Epoch 44/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.6483\n",
            "Epoch 45/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.6498\n",
            "Epoch 46/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.6410\n",
            "Epoch 47/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.6378\n",
            "Epoch 48/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.6316\n",
            "Epoch 49/50\n",
            "992/992 [==============================] - 26s 27ms/step - loss: 0.6233\n",
            "Epoch 50/50\n",
            "992/992 [==============================] - 26s 26ms/step - loss: 0.6128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = 'the meaning of life'\n",
        "input_one_hot = np.zeros((len(input), T, len(chars)), dtype='bool')"
      ],
      "metadata": {
        "id": "rHu9MSoca-CD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_buffer = input_one_hot[0]\n",
        "generated_text = input\n",
        "\n",
        "yy = []\n",
        "for i in range(200):\n",
        "    yhat = model_freestyle.predict(input_buffer[None,:])\n",
        "    # sample the next character:\n",
        "    # ix = np.argmax(yhat)\n",
        "    ix = np.random.choice(range(len(chars)), p=yhat[0])\n",
        "    ch = ix_to_char[ix]\n",
        "    generated_text += ch\n",
        "    # update the input buffer:\n",
        "    input_buffer = np.r_[input_buffer[1:,:], np.zeros((1,len(chars)))]\n",
        "    input_buffer[-1,ix] = 1\n",
        "    yy.append(yhat)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "uFVn38AfnHV2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74b5d93e-a75c-4734-cea3-f811df27fc8e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the meaning of lifee en 10 billion is child on fornews of no all of the factowfornthillary clinton lillion the onested can everyone can health care aed opportunity to donald trump work realdonaldtrump neid oornews who l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_freestyle = Sequential(name='freestyle')\n",
        "model_freestyle.add(Input(shape=(T, len(chars))))  # (12,27)\n",
        "model_freestyle.add(LSTM(128)) # 128 internal state units\n",
        "model_freestyle.add(Dense(len(chars), activation=\"softmax\"))\n",
        "model_freestyle.summary()\n",
        "model_freestyle.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
      ],
      "metadata": {
        "id": "XTd16j4simsz",
        "outputId": "7e903c24-adb6-4a89-e6ca-4a08b73a6ed5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"freestyle\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_5 (LSTM)               (None, 128)               84992     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 37)                4773      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 89,765\n",
            "Trainable params: 89,765\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_freestyle.fit(X, Y, epochs=60, batch_size=50)\n",
        "input = 'the meaning of life'\n",
        "input_one_hot = np.zeros((len(input), T, len(chars)), dtype='bool')"
      ],
      "metadata": {
        "id": "fpVcNgjYjAf4",
        "outputId": "4fe3058e-a4ca-43c7-8a5b-b953840dc036",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "1388/1388 [==============================] - 9s 5ms/step - loss: 2.6395\n",
            "Epoch 2/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 2.2856\n",
            "Epoch 3/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 2.1369\n",
            "Epoch 4/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 2.0294\n",
            "Epoch 5/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.9476\n",
            "Epoch 6/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.8814\n",
            "Epoch 7/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.8248\n",
            "Epoch 8/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.7735\n",
            "Epoch 9/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.7281\n",
            "Epoch 10/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.6864\n",
            "Epoch 11/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.6469\n",
            "Epoch 12/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.6087\n",
            "Epoch 13/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.5745\n",
            "Epoch 14/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.5409\n",
            "Epoch 15/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.5073\n",
            "Epoch 16/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.4746\n",
            "Epoch 17/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.4457\n",
            "Epoch 18/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.4150\n",
            "Epoch 19/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.3875\n",
            "Epoch 20/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.3594\n",
            "Epoch 21/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.3330\n",
            "Epoch 22/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.3080\n",
            "Epoch 23/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.2837\n",
            "Epoch 24/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.2627\n",
            "Epoch 25/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.2416\n",
            "Epoch 26/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.2226\n",
            "Epoch 27/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.2068\n",
            "Epoch 28/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.1868\n",
            "Epoch 29/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.1724\n",
            "Epoch 30/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.1589\n",
            "Epoch 31/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.1449\n",
            "Epoch 32/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.1333\n",
            "Epoch 33/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.1188\n",
            "Epoch 34/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.1108\n",
            "Epoch 35/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.1007\n",
            "Epoch 36/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.0918\n",
            "Epoch 37/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.0823\n",
            "Epoch 38/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.0738\n",
            "Epoch 39/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.0664\n",
            "Epoch 40/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.0598\n",
            "Epoch 41/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.0526\n",
            "Epoch 42/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.0443\n",
            "Epoch 43/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.0389\n",
            "Epoch 44/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.0333\n",
            "Epoch 45/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.0264\n",
            "Epoch 46/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.0162\n",
            "Epoch 47/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.0141\n",
            "Epoch 48/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.0053\n",
            "Epoch 49/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 1.0014\n",
            "Epoch 50/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 0.9978\n",
            "Epoch 51/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 0.9966\n",
            "Epoch 52/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 0.9916\n",
            "Epoch 53/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 0.9867\n",
            "Epoch 54/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 0.9807\n",
            "Epoch 55/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 0.9734\n",
            "Epoch 56/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 0.9690\n",
            "Epoch 57/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 0.9665\n",
            "Epoch 58/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 0.9649\n",
            "Epoch 59/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 0.9595\n",
            "Epoch 60/60\n",
            "1388/1388 [==============================] - 7s 5ms/step - loss: 0.9547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_buffer = input_one_hot[0]\n",
        "generated_text = input\n",
        "\n",
        "yy = []\n",
        "for i in range(200):\n",
        "    yhat = model_freestyle.predict(input_buffer[None,:])\n",
        "    # sample the next character:\n",
        "    # ix = np.argmax(yhat)\n",
        "    ix = np.random.choice(range(len(chars)), p=yhat[0])\n",
        "    ch = ix_to_char[ix]\n",
        "    generated_text += ch\n",
        "    # update the input buffer:\n",
        "    input_buffer = np.r_[input_buffer[1:,:], np.zeros((1,len(chars)))]\n",
        "    input_buffer[-1,ix] = 1\n",
        "    yy.append(yhat)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "WEBCtGOTjEEM",
        "outputId": "bea0421f-35f4-4443-e0b4-d90b0d3f8bcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the meaning of lifeket no the mettrubp beckity of everyone clunte we will make america great againnettlenk agreitwhip  mastreys to be about the first all saxelve in therellang liy to have they armom at we repted a ve go\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhpeQDqg9R_h"
      },
      "source": [
        "***\n",
        "## Good Luck!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "ex10.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}