{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergienko4/deep-learing/blob/main/ex10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaMoU7zn9R_P"
      },
      "source": [
        "# Deep Learning: Ex.10 - RNN\n",
        "\n",
        "Submitted by: [... **your name and ID** ...]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oN_6bfHZ9R_S",
        "outputId": "62b9cd86-9acc-481b-b00b-021926509c3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM # <--- recurrent layers\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from seaborn import heatmap\n",
        "import re\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path='/content/drive/MyDrive/ex10/war_and_peace.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ0BtfeM9bli",
        "outputId": "8586518c-38f9-4a49-a542-9a1cdabd8879"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8i2f2p29R_V"
      },
      "source": [
        "***\n",
        "### 1. Preprocess the text corpus\n",
        "\n",
        "(if you are using google colab, remember to upload the corpus file first..)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L8JLzkR9R_X",
        "outputId": "419cf2f4-d83e-4bde-eaf3-a0d529e482f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(text) =  3196213\n",
            "well prince so genoa and lucca are now just family estates of the buonapartes but i warn you if you dont tell me that this means war if you still try to defend the infamies and horrors perpetrated by that antichristi really believe he is antichristi will have nothing more to do with you and you are no longer my friend no longer my faithful slave as you call yourself but how do you do i see i have \n"
          ]
        }
      ],
      "source": [
        "# f = open('war_and_peace.txt','r') # open the corpus file\n",
        "f = open(path,'r') \n",
        "text = f.read().lower()  # read file and convert to lower-case letters\n",
        "data = text.replace('\\n',' ')\n",
        "\n",
        "data = re.sub(r'[^a-zA-Z0-9 ]',r'',data)\n",
        "\n",
        "print('len(text) = ',len(text))\n",
        "\n",
        "print(data[:400]) # print the first 400 characters.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C86ydp0A9R_Y"
      },
      "source": [
        "- generate training sequences of `T=20` characters, by sampling the text corpus with a stride of 5 characters (i.e., each sequences starts 5 chars after the begining of the last sequences).\n",
        "\n",
        "- generate a matching list, holding the `next_char` for each of your sequences.\n",
        "\n",
        "- how many sequences did you extract in total? `N = ?`\n",
        "\n",
        "- convert the sequences into a 1-hot representation, suitable for our model trainig:\n",
        "\n",
        "`X.shape = (N, T, len(chars))`\n",
        "\n",
        "`Y.shape = (N, len(chars))`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(data)))\n",
        "data_size, vocab_size = len(data), len(chars)\n",
        "print('There are %d total characters and %d unique characters in your data.' % (data_size, vocab_size))\n",
        "print('chars = ',chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsmUFYMIEj43",
        "outputId": "9042cdd2-e10c-4e5e-c14e-43c665e08e2a"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 3083435 total characters and 37 unique characters in your data.\n",
            "chars =  [' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
        "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
        "\n",
        "# ix_to_char"
      ],
      "metadata": {
        "id": "O7zbsDRSE8il"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T = 20  # extract training sequences of length T\n",
        "stride = 5\n",
        "\n",
        "sequences = []  # This holds our extracted sequences\n",
        "next_chars = []  # This holds the targets (the follow-up character)\n",
        "\n",
        "for i in range(0, len(data) - T, stride):\n",
        "    sequences.append(data[i: i + T])\n",
        "    next_chars.append(data[i + T])"
      ],
      "metadata": {
        "id": "9gLw2yBjFqMp"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(sequences), T, len(chars)), dtype='bool')\n",
        "Y = np.zeros((len(sequences), len(chars)), dtype='bool')\n",
        "\n",
        "for i, seq in enumerate(sequences):\n",
        "    for t, char in enumerate(seq):\n",
        "        X[i, t, char_to_ix[char]] = 1\n",
        "    Y[i, char_to_ix[next_chars[i]]] = 1\n",
        "    \n",
        "print('X.shape = (#examples, T, input-dim) =', X.shape)\n",
        "print('Y.shape = (#examples, output-dim) =', Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqQgDtlDFyHV",
        "outputId": "a2f34a4f-a097-4a93-a9ef-d7bc63c1692d"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X.shape = (#examples, T, input-dim) = (616683, 20, 37)\n",
            "Y.shape = (#examples, output-dim) = (616683, 37)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15DwlbpW9R_b"
      },
      "source": [
        "***\n",
        "### 2. LTSM Model\n",
        "\n",
        "- Build an `LTSM` model with 128 (hidden)-units that accepts the input sequences. Add a `Dense` layer on top of it, with `len(chars)` softmax units.\n",
        "\n",
        "- Train the model for only 1 epoch (use: `RMSprop` and batch size of 128).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential(name='LSTM_128')\n",
        "model.add(Input(shape=(T, len(chars))))  # (12,27)\n",
        "model.add(LSTM(128)) # 128 internal state units\n",
        "model.add(Dense(len(chars), activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "XH4ux8GdMazW",
        "outputId": "273a4396-545f-49f0-c29b-ddb731b9a802",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"LSTM_128\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_7 (LSTM)               (None, 128)               84992     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 37)                4773      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 89,765\n",
            "Trainable params: 89,765\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "history = model.fit(X, Y, epochs=1, batch_size=128)"
      ],
      "metadata": {
        "id": "SVta-HkVNVD8",
        "outputId": "2faef8f3-5c9e-46c2-b936-a43680896b84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4818/4818 [==============================] - 19s 4ms/step - loss: 2.0254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjfbZqIZ9R_d"
      },
      "source": [
        "### 3. Model predictions\n",
        "\n",
        "\n",
        "- use the senternce `the meaning of life ` as an input to the model (convert it to 1-hot first..),\n",
        "\n",
        "- plot the model's output as a probability distribution over the list of chars.\n",
        "\n",
        "- sample a single char from that distribution, and add it to the generated sentence.\n",
        "\n",
        "- update the 1-hot buffer, and continue the process for 99 more letters (using a loop).\n",
        "\n",
        "- print the resulting sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "QdnGKgvU9R_e"
      },
      "outputs": [],
      "source": [
        "input = 'the meaning of life'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_one_hot = np.zeros((len(input), T, len(chars)), dtype='bool')"
      ],
      "metadata": {
        "id": "p1NTrpq-OZhy"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_one_hot.shape"
      ],
      "metadata": {
        "id": "j0xk3tYdP3Yf",
        "outputId": "e18acf56-d714-4a85-cea3-aeb73f5bdde1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19, 20, 37)"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = model.predict(input_one_hot)"
      ],
      "metadata": {
        "id": "4iolT6PkOqJU"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14,4))\n",
        "plt.bar(range(len(chars)), y_hat[0])\n",
        "plt.xticks(range(len(chars)), labels=chars)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LRuGNqAIPIWs",
        "outputId": "6061a7ca-d523-4800-e3cf-79e1d6ec964f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_buffer = input_one_hot[0]\n",
        "generated_text = input\n",
        "\n",
        "yy = []\n",
        "for i in range(100):\n",
        "    yhat = model.predict(input_buffer[None,:])\n",
        "    # sample the next character:\n",
        "    # ix = np.argmax(yhat)\n",
        "    ix = np.random.choice(range(len(chars)), p=yhat[0])\n",
        "    ch = ix_to_char[ix]\n",
        "    generated_text += ch\n",
        "    # update the input buffer:\n",
        "    input_buffer = np.r_[input_buffer[1:,:], np.zeros((1,len(chars)))]\n",
        "    input_buffer[-1,ix] = 1\n",
        "    yy.append(yhat)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "hLgnagExUDR0",
        "outputId": "1ead88b7-42e8-492f-bc34-6b43c85cdf05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the meaning of lifet all by hosk he papren frimply thement comout a bening ate poiceted with be the rome sores notha th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uaqpz4zJ9R_f"
      },
      "source": [
        "***\n",
        "### 3. Fit your model\n",
        "\n",
        "- Fit your model a bit more (try 10-20 epochs), and regenerate a new `N=100` sentence sample. Does it get any better?\n",
        "\n",
        "- If you wish, you can try to train the model further, or you can try using a different corpus (dataset) for the training (you can even try a text in hebrew). Be creative ;)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, Y, epochs=20, batch_size=512)"
      ],
      "metadata": {
        "id": "ts6vlqWEUm5O",
        "outputId": "fc8f6547-ba7a-40d1-c104-bb1ab5e03011",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.6765\n",
            "Epoch 2/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.5844\n",
            "Epoch 3/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.5228\n",
            "Epoch 4/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.4772\n",
            "Epoch 5/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.4417\n",
            "Epoch 6/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.4132\n",
            "Epoch 7/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.3898\n",
            "Epoch 8/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.3701\n",
            "Epoch 9/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.3531\n",
            "Epoch 10/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.3384\n",
            "Epoch 11/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.3251\n",
            "Epoch 12/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.3135\n",
            "Epoch 13/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.3032\n",
            "Epoch 14/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.2935\n",
            "Epoch 15/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.2849\n",
            "Epoch 16/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.2767\n",
            "Epoch 17/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.2695\n",
            "Epoch 18/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.2623\n",
            "Epoch 19/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.2562\n",
            "Epoch 20/20\n",
            "1205/1205 [==============================] - 6s 5ms/step - loss: 1.2502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nL10liRv9R_g",
        "outputId": "dc4d1098-4bd4-400f-c538-ef623f0f354f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the meaning of life of the ponceov which they refulting he to let her most and pierre lakeness that the staff of life a\n"
          ]
        }
      ],
      "source": [
        "input_buffer = input_one_hot[0]\n",
        "generated_text = input\n",
        "\n",
        "yy = []\n",
        "for i in range(100):\n",
        "    yhat = model.predict(input_buffer[None,:])\n",
        "    # sample the next character:\n",
        "    # ix = np.argmax(yhat)\n",
        "    ix = np.random.choice(range(len(chars)), p=yhat[0])\n",
        "    ch = ix_to_char[ix]\n",
        "    generated_text += ch\n",
        "    # update the input buffer:\n",
        "    input_buffer = np.r_[input_buffer[1:,:], np.zeros((1,len(chars)))]\n",
        "    input_buffer[-1,ix] = 1\n",
        "    yy.append(yhat)\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "wvtNTixKgW9t",
        "outputId": "5c789180-1d35-45aa-e621-543bbf9b7740",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(616683, 20, 37)"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#---------------------------------------------------freestyle---------------------------------------------------"
      ],
      "metadata": {
        "id": "RXeWpx4utCH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_freestyle = Sequential(name='freestyle')\n",
        "model_freestyle.add(LSTM(\n",
        "        256,\n",
        "        input_shape=(X.shape[1], X.shape[2]),\n",
        "        return_sequences=True\n",
        "    ))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(LSTM(512, return_sequences=True))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(LSTM(256))\n",
        "model_freestyle.add(Dense(256))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(Dense(vocab_size))\n",
        "model_freestyle.add(Activation('softmax'))\n",
        "model_freestyle.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "model_freestyle.summary()\n"
      ],
      "metadata": {
        "id": "F3350UHwfT1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_freestyle.fit(X, Y, epochs=50, batch_size=1024)"
      ],
      "metadata": {
        "id": "uvwsS5cyhD_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_buffer = input_one_hot[0]\n",
        "generated_text = input\n",
        "\n",
        "yy = []\n",
        "for i in range(100):\n",
        "    yhat = model.predict(input_buffer[None,:])\n",
        "    # sample the next character:\n",
        "    # ix = np.argmax(yhat)\n",
        "    ix = np.random.choice(range(len(chars)), p=yhat[0])\n",
        "    ch = ix_to_char[ix]\n",
        "    generated_text += ch\n",
        "    # update the input buffer:\n",
        "    input_buffer = np.r_[input_buffer[1:,:], np.zeros((1,len(chars)))]\n",
        "    input_buffer[-1,ix] = 1\n",
        "    yy.append(yhat)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "f8MmWbrojX6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path='/content/drive/MyDrive/ex10/russian_troll_tweets_.txt'\n",
        "# f = open('war_and_peace.txt','r') # open the corpus file\n",
        "f = open(path,'r') \n",
        "text = f.read().lower()  # read file and convert to lower-case letters\n",
        "data = text.replace('\\n','.')\n",
        "\n",
        "# data = re.sub(r'[^a-zA-Z0-9 ]',r'',data)\n",
        "\n",
        "print('len(text) = ',len(text))\n",
        "\n",
        "print(data[:400]) # print the first 400 characters..\n",
        "\n",
        "chars = sorted(list(set(data)))\n",
        "data_size, vocab_size = len(data), len(chars)\n",
        "print('There are %d total characters and %d unique characters in your data.' % (data_size, vocab_size))\n",
        "print('chars = ',chars)\n",
        "\n",
        "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
        "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
        "\n",
        "T = 50  # extract training sequences of length T\n",
        "stride = 10\n",
        "\n",
        "sequences = []  # This holds our extracted sequences\n",
        "next_chars = []  # This holds the targets (the follow-up character)\n",
        "\n",
        "for i in range(0, len(data) - T, stride):\n",
        "    sequences.append(data[i: i + T])\n",
        "    next_chars.append(data[i + T])\n",
        "\n",
        "X = np.zeros((len(sequences), T, len(chars)), dtype='bool')\n",
        "Y = np.zeros((len(sequences), len(chars)), dtype='bool')\n",
        "\n",
        "for i, seq in enumerate(sequences):\n",
        "    for t, char in enumerate(seq):\n",
        "        X[i, t, char_to_ix[char]] = 1\n",
        "    Y[i, char_to_ix[next_chars[i]]] = 1\n",
        "\n",
        "print('X.shape = (#examples, T, input-dim) =', X.shape)\n",
        "print('Y.shape = (#examples, output-dim) =', Y.shape)"
      ],
      "metadata": {
        "id": "-btE9iMTl-wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_freestyle = Sequential(name='freestyle')\n",
        "model_freestyle.add(LSTM(\n",
        "        256,\n",
        "        input_shape=(X.shape[1], X.shape[2]),\n",
        "        return_sequences=True\n",
        "    ))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(LSTM(512, return_sequences=True))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(LSTM(256))\n",
        "model_freestyle.add(Dense(256))\n",
        "model_freestyle.add(Dropout(0.3))\n",
        "model_freestyle.add(Dense(vocab_size))\n",
        "model_freestyle.add(Activation('softmax'))\n",
        "model_freestyle.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "model_freestyle.summary()"
      ],
      "metadata": {
        "id": "Rb9DF5eMm5ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_freestyle.fit(X, Y, epochs=50, batch_size=1024)"
      ],
      "metadata": {
        "id": "VNY9fvvbm9I3",
        "outputId": "0b474c00-1ecb-4163-c4a4-50df0e4d99b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "148/148 [==============================] - 13s 65ms/step - loss: 3.2693\n",
            "Epoch 2/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 2.8500\n",
            "Epoch 3/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 2.5140\n",
            "Epoch 4/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 2.3068\n",
            "Epoch 5/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 2.1430\n",
            "Epoch 6/50\n",
            "148/148 [==============================] - 10s 66ms/step - loss: 2.0019\n",
            "Epoch 7/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 1.8842\n",
            "Epoch 8/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 1.7859\n",
            "Epoch 9/50\n",
            "148/148 [==============================] - 10s 67ms/step - loss: 1.7040\n",
            "Epoch 10/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 1.6309\n",
            "Epoch 11/50\n",
            "148/148 [==============================] - 10s 66ms/step - loss: 1.5711\n",
            "Epoch 12/50\n",
            "148/148 [==============================] - 10s 67ms/step - loss: 1.5149\n",
            "Epoch 13/50\n",
            "148/148 [==============================] - 10s 66ms/step - loss: 1.4597\n",
            "Epoch 14/50\n",
            "148/148 [==============================] - 10s 66ms/step - loss: 1.4112\n",
            "Epoch 15/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 1.3639\n",
            "Epoch 16/50\n",
            "148/148 [==============================] - 10s 66ms/step - loss: 1.3197\n",
            "Epoch 17/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 1.2777\n",
            "Epoch 18/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 1.2348\n",
            "Epoch 19/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 1.1906\n",
            "Epoch 20/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 1.1511\n",
            "Epoch 21/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 1.1082\n",
            "Epoch 22/50\n",
            "148/148 [==============================] - 10s 66ms/step - loss: 1.0717\n",
            "Epoch 23/50\n",
            "148/148 [==============================] - 10s 66ms/step - loss: 1.0319\n",
            "Epoch 24/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 0.9979\n",
            "Epoch 25/50\n",
            "148/148 [==============================] - 10s 67ms/step - loss: 0.9610\n",
            "Epoch 26/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 0.9273\n",
            "Epoch 27/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 0.8935\n",
            "Epoch 28/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 0.8644\n",
            "Epoch 29/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 0.8370\n",
            "Epoch 30/50\n",
            "148/148 [==============================] - 10s 66ms/step - loss: 0.8092\n",
            "Epoch 31/50\n",
            "148/148 [==============================] - 10s 66ms/step - loss: 0.7843\n",
            "Epoch 32/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 0.7609\n",
            "Epoch 33/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 0.7386\n",
            "Epoch 34/50\n",
            "148/148 [==============================] - 10s 66ms/step - loss: 0.7135\n",
            "Epoch 35/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 0.6951\n",
            "Epoch 36/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 0.6795\n",
            "Epoch 37/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 0.6591\n",
            "Epoch 38/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 0.6421\n",
            "Epoch 39/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 0.6257\n",
            "Epoch 40/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 0.6133\n",
            "Epoch 41/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 0.5944\n",
            "Epoch 42/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 0.5859\n",
            "Epoch 43/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 0.5732\n",
            "Epoch 44/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 0.5601\n",
            "Epoch 45/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 0.5537\n",
            "Epoch 46/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 0.5393\n",
            "Epoch 47/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 0.5312\n",
            "Epoch 48/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 0.5231\n",
            "Epoch 49/50\n",
            "148/148 [==============================] - 10s 65ms/step - loss: 0.5149\n",
            "Epoch 50/50\n",
            "103/148 [===================>..........] - ETA: 2s - loss: 0.4988"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_buffer = input_one_hot[0]\n",
        "generated_text = input\n",
        "\n",
        "yy = []\n",
        "for i in range(200):\n",
        "    yhat = model.predict(input_buffer[None,:])\n",
        "    # sample the next character:\n",
        "    # ix = np.argmax(yhat)\n",
        "    ix = np.random.choice(range(len(chars)), p=yhat[0])\n",
        "    ch = ix_to_char[ix]\n",
        "    generated_text += ch\n",
        "    # update the input buffer:\n",
        "    input_buffer = np.r_[input_buffer[1:,:], np.zeros((1,len(chars)))]\n",
        "    input_buffer[-1,ix] = 1\n",
        "    yy.append(yhat)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "uFVn38AfnHV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhpeQDqg9R_h"
      },
      "source": [
        "***\n",
        "## Good Luck!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "ex10.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}