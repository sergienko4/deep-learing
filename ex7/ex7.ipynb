{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDKo_4Yx242s"
      },
      "source": [
        "# Deep Learning: Ex.7 - **Object detection**\n",
        "\n",
        "Submitted by: [... **your name and ID** ...]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwXAuoQk2rIY"
      },
      "outputs": [],
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "import tensorflow_hub as hub  # <---- https://tfhub.dev\n",
        "\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle  # <---- to draw rectangles "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeoR1VuX3Cgw"
      },
      "source": [
        "---\n",
        "### 1. Object detection\n",
        "\n",
        "Let's pick one of the `Faster R-CNN` models from TF-Hub:\n",
        " https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_640x640/1\n",
        "\n",
        "As mentioned in this URL (check it), the model was trained on the **COCO 2017 dataset**. You will need the class labels of this dataset, which is provided in the \n",
        "`mscoco_label_map.pbtxt` file. Upload the file to your Colab notebook (drag-and-drop) and use the following code to extract the labels from it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_label_map(label_map_path):\n",
        "    item_id = None\n",
        "    item_name = None\n",
        "    items = {}\n",
        "    with open(label_map_path, \"r\") as file:\n",
        "        for line in file:\n",
        "            line.replace(\" \", \"\")\n",
        "            if line == \"item{\":\n",
        "                pass\n",
        "            elif line == \"}\":\n",
        "                pass\n",
        "            elif \"id\" in line:\n",
        "                item_id = int(line.split(\":\", 1)[1].strip())\n",
        "            elif \"display_name\" in line:\n",
        "                item_name = line.split(\":\", 1)[1].replace(\"\\\"\", \"\").strip()\n",
        "\n",
        "            if item_id is not None and item_name is not None:\n",
        "                items[item_id] = item_name\n",
        "                item_id = None\n",
        "                item_name = None\n",
        "    return items\n",
        "\n",
        "# load \"mscoco\" labels\n",
        "labels =  read_label_map('mscoco_label_map.pbtxt')\n",
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Load and run the trained model for each of the images given in this exercise.\n",
        "\n",
        "- For each image, plot a graph of the detection scores.\n",
        "\n",
        "- For each image, set a minimal score threshold, and plot the final image with the detected objects (marked with their class name and score).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GUwdFD-3C0i"
      },
      "outputs": [],
      "source": [
        "    ################################\n",
        "    ###  your code goes here...  ###\n",
        "    ################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QU4U5Cq4kIZ"
      },
      "source": [
        "---\n",
        "### 2. Let's try a different model\n",
        "\n",
        "As noticed, the 'bugs' image was not labeled correctly, as there is  no 'beetle' class in the MS-COCO dataset.\n",
        "\n",
        "Let's pick a different model:\n",
        "https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\n",
        "\n",
        "This model was trained over the **OpenImagesV4 dataset** (1.7M images with 600 object classes).\n",
        "\n",
        "- Run this model on the 'bugs' image, and display the results.\n",
        "\n",
        "Note that you can get the detection class names, directly from the model (see the `example use` section in the model's URL)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9OxYkyVETAO"
      },
      "outputs": [],
      "source": [
        "    ################################\n",
        "    ###  your code goes here...  ###\n",
        "    ################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqplCixAEpJS"
      },
      "source": [
        "---\n",
        "### 3. Keypoints detection\n",
        "\n",
        "Some of the models, trained on the **MS-COCO datasets**, include not only the bounding boxes of the objects, but also a set of **17 keypoints** for each of the persons detected in the image (e.g., elbows, head, knees, hands, etc...).\n",
        "\n",
        "Pick one such model, e.g:\n",
        "https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512_kpts/1\n",
        "\n",
        "As noted in the URL, these 17 keypoints are returned as:\n",
        "\n",
        "`detection_keypoints: a tf.float32 tensor of shape [1, N, 17, 2] containing the detected keypoints.`\n",
        "\n",
        "- For each person detected in the image, plot its 17 keypoints. In addition, draw the \"skeleton\" for each person, by connecting the lines between the keypoints. Use the provided mapping: `COCO17_HUMAN_POSE_KEYPOINTS`. For example: `COCO17_HUMAN_POSE_KEYPOINTS[0] = (0,1)` means that you need to draw a line between keypoint 0 to keypoint 1. See lecture slides for details.\n",
        "\n",
        "- Run the model and display the results, for all the images containing any persons.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yWuIHoJFrk5"
      },
      "outputs": [],
      "source": [
        "COCO17_HUMAN_POSE_KEYPOINTS = [(0, 1),\n",
        " (0, 2),\n",
        " (1, 3),\n",
        " (2, 4),\n",
        " (0, 5),\n",
        " (0, 6),\n",
        " (5, 7),\n",
        " (7, 9),\n",
        " (6, 8),\n",
        " (8, 10),\n",
        " (5, 6),\n",
        " (5, 11),\n",
        " (6, 12),\n",
        " (11, 12),\n",
        " (11, 13),\n",
        " (13, 15),\n",
        " (12, 14),\n",
        " (14, 16)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNUsT-J-HF0q"
      },
      "outputs": [],
      "source": [
        "    ################################\n",
        "    ###  your code goes here...  ###\n",
        "    ################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01Mzq5gAHcAz"
      },
      "source": [
        "***\n",
        "## Good Luck!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled68.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
