{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "ex2.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergienko4/deep-learing/blob/main/ex2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQb47c65dAZA"
      },
      "source": [
        "# Deep Learning: Ex.2 - Multilayer Perceptron \n",
        "\n",
        "Submitted by: [... **name & ID** ...]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRery5-8dAZF"
      },
      "source": [
        "# TensorFlow \n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wHjfOUedAZH"
      },
      "source": [
        "---\n",
        "In this exercise we will work with two datasets (see `class2.ipynb` for details): \n",
        "- **MNIST**: handwritten digits (0-9), each sample is an image of size 28x28 (without colors)\n",
        "- **CIFAR-10**: color images of 10 classes (airplanes, birds, etc..), each sample is of size 32x32x**3**\n",
        "\n",
        "We will try to fit different models for each of these datasets:\n",
        "1. **0-hidden:** simplest model, without any hidden layers\n",
        "2. **1-hidden:** a model with one hidden layer (with 32 neurons in that layer)\n",
        "3. **2-hidden:** a model with two hidden layer (with 32 neurons in each of these hidden layers)\n",
        "\n",
        "\n",
        "General instructions:\n",
        "\n",
        "- For each model, the input layer is the images (after flatten it to long vector), and the output layer is a `softmax` of 10 units (one unit for each class).\n",
        "\n",
        "- Activations: use `ReLU` for the hidden-layers, and `softmat` for the output layer.\n",
        "\n",
        "- Display the `model.summary()` for each model.\n",
        "\n",
        "- Train each model for **50 epochs** (use: `batch_size=64` and `verbose=0`).\n",
        "\n",
        "- For each model, **plot the training loss & accuracy plots**.\n",
        "\n",
        "- Summarize the results of all models (for both datasets) in the table below (by editing this markup cell):\n",
        "\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Dataset</th>\n",
        "    <th>Model</th>\n",
        "    <th>#parameters</th>\n",
        "    <th>train accuracy</th>\n",
        "    <th>test accuracy</th>\n",
        "  </tr>\n",
        "    \n",
        "  <!-- copy this block once for every model/dataset you tested -->  \n",
        "  <tr> \n",
        "    <td>MNIST</td>   <!-- Dataset -->  \n",
        "    <td>0-hidden</td>   <!-- Model -->\n",
        "    <td>??? </td> <!-- #parameters -->\n",
        "    <td>???</td> <!-- train accuracy -->\n",
        "    <td>???</td> <!-- test accuracy -->\n",
        "  </tr>\n",
        "    \n",
        " \n",
        "</table>\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR1DMHXCdAZJ"
      },
      "source": [
        "#### Loading the MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRNd0C1jdAZJ"
      },
      "source": [
        "# 1. load/download the data\n",
        "(MNIST_train_images, MNIST_train_labels), (MNIST_test_images, MNIST_test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# 2. flatten the labels (easier to deal with)\n",
        "MNIST_train_labels = MNIST_train_labels.flatten()  # (50000, 1) -> (50000,)\n",
        "MNIST_test_labels = MNIST_test_labels.flatten()    # (10000, 1) -> (10000,)\n",
        "\n",
        "# 3. convert uint8->float32 and normalize range to 0.0-1.0 \n",
        "MNIST_train_images = MNIST_train_images.astype('float32') / 255.0\n",
        "MNIST_test_images = MNIST_test_images.astype('float32') / 255.0\n",
        "\n",
        "# 4. expand the dimensions (tensorflow expects images in a (H,W,C) format):\n",
        "# (Height, Width, Channel), in our case we have 3 color channels (R,G,B)\n",
        "MNIST_train_images = MNIST_train_images[...,None]\n",
        "MNIST_test_images = MNIST_test_images[..., None]\n",
        "\n",
        "# 5. print the shapes\n",
        "print('MNIST_train_images.shape =',MNIST_train_images.shape)\n",
        "print('MNIST_train_labels.shape =',MNIST_train_labels.shape)\n",
        "print('MNIST_test_images.shape =',MNIST_test_images.shape)\n",
        "print('MNIST_test_labels.shape =',MNIST_test_labels.shape)\n",
        "\n",
        "# 6. lets plot some \"5\"s (just for fun)\n",
        "[idx] = np.where(MNIST_train_labels==5) # find all the \"5\"s\n",
        "plt.figure(figsize=(15,8))\n",
        "for i in range(50):\n",
        "    plt.subplot(5,10,i+1)\n",
        "    plt.imshow(MNIST_train_images[idx[i],:,:,0], cmap='gray')\n",
        "    plt.xticks([]), plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVnvAcCidAZL"
      },
      "source": [
        "---\n",
        "#### Loading the CIFAR-10 Dataset\n",
        "\n",
        "When running this command for the first time, it will download dataset from a remote server, which might take some time.. (in case of server error - just try again a bit later)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDSYaWuPdAZL"
      },
      "source": [
        "# 1. load/download the data\n",
        "(CIFAR_train_images, CIFAR_train_labels), (CIFAR_test_images, CIFAR_test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# 2. flatten the labels (easier to deal with)\n",
        "CIFAR_train_labels = CIFAR_train_labels.flatten()  # (50000, 1) -> (50000,)\n",
        "CIFAR_test_labels = CIFAR_test_labels.flatten()    # (10000, 1) -> (10000,)\n",
        "\n",
        "# 3. convert uint8->float32 and normalize range to 0.0-1.0 \n",
        "CIFAR_train_images = CIFAR_train_images.astype('float32') / 255.0\n",
        "CIFAR_test_images = CIFAR_test_images.astype('float32') / 255.0\n",
        "\n",
        "# 4. define the 10 classes names\n",
        "CIFAR_class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# 5. print the shapes\n",
        "print('CIFAR_train_images.shape =',CIFAR_train_images.shape)\n",
        "print('CIFAR_train_labels.shape =',CIFAR_train_labels.shape)\n",
        "print('CIFAR_test_images.shape =',CIFAR_test_images.shape)\n",
        "print('CIFAR_test_labels.shape =',CIFAR_test_labels.shape)\n",
        "\n",
        "# 6. lets plot some 'dogs' (just for fun)\n",
        "[idx] = np.where(CIFAR_train_labels==5) # find all the dogs\n",
        "plt.figure(figsize=(15,8))\n",
        "for i in range(50):\n",
        "    plt.subplot(5,10,i+1)\n",
        "    plt.imshow(CIFAR_train_images[idx[i]])\n",
        "    plt.xticks([]), plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuQPD-5TdAZL"
      },
      "source": [
        "***\n",
        "#### 1. MNIST with 0-hidden\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0feYMfadAZN"
      },
      "source": [
        "    ###########################\n",
        "    ###  your code here...  ###\n",
        "    ###########################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BCCDsMwdAZN"
      },
      "source": [
        "***\n",
        "#### 2. MNIST with 1-hidden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yfK9OAadAZO"
      },
      "source": [
        "    ###########################\n",
        "    ###  your code here...  ###\n",
        "    ###########################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8-8jI2vdAZP"
      },
      "source": [
        "***\n",
        "#### 3. MNIST with 2-hidden\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F377yjl4dAZQ"
      },
      "source": [
        "    ###########################\n",
        "    ###  your code here...  ###\n",
        "    ###########################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCcXXO6cdAZQ"
      },
      "source": [
        "***\n",
        "#### 4. CIFAR with 0-hidden\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfOPgJZKdAZR"
      },
      "source": [
        "    ###########################\n",
        "    ###  your code here...  ###\n",
        "    ###########################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHbYBz5ndAZS"
      },
      "source": [
        "***\n",
        "#### 5. CIFAR with 1-hidden\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5QByZe0dAZS"
      },
      "source": [
        "    ###########################\n",
        "    ###  your code here...  ###\n",
        "    ###########################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkMIoC_LdAZU"
      },
      "source": [
        "***\n",
        "#### 6. CIFAR with 2-hidden\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7pXH2YQdAZU"
      },
      "source": [
        "    ###########################\n",
        "    ###  your code here...  ###\n",
        "    ###########################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKTt32hQdAZU"
      },
      "source": [
        "***\n",
        "\n",
        "## Good Luck!\n",
        "\n",
        "- **don't forget to fill the summary table on the top !!**\n"
      ]
    }
  ]
}